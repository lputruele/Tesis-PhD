\chapter{Medidas para Masking-tolerancia a fallas}
\label{cap:maskingMeasure}

Introducimos una noción de distancia de tolerancia a fallas entre sistemas de transición etiquetados. Intuitivamente, esta noción de distancia mide el grado de tolerancia a fallas exhibido por un sistema candidato.
En la práctica, hay diferentes tipos de tolerancia a fallas, aquí nos restringimos al análisis de masking-tolerancia a fallas ya que suele ser una característica muy deseada para sistemas críticos.
En términos generales, un sistema es masking-tolerante a fallas cuando es capaz de enmascarar las fallas completamente, sin permitir que estas fallas tengan consecuencias observables para los usuarios.
Capturamos la masking-tolerancia a fallas mediante una relación de simulación, acompañada por una caracterización correspondiente en términos de juegos.
Enriquecemos además estos juegos con objetivos cuantitativos para así definir la noción de distancia de masking-tolerancia a fallas.
Además, investigamos las propiedades básicas de esta noción de distancia de masking y probamos que es una semi-métrica dirigida.
Demostramos que, en el caso de sistemas deterministas, computar la distancia de masking se puede lograr utilizando un algoritmo de camino más corto.
Por otro lado, para sistemas no deterministas este cómputo se realiza por medio de técnicas de punto fijo. % No se como traducir approach
Estos algoritmos fueron implementados en una herramienta que computa de manera automática la distancia de masking entre un sistema nominal y una versión del mismo que agrega fallas (y mecanismos de tolerancia). Hemos evaluado su desempeño y efectividad sobre varios casos de estudio de diferentes complejidades.

\section{Introducción} \label{sec:intro}

    La tolerancia a fallas es una característica importante del software crítico, y puede ser definida como la capacidad de un sistema para lidiar con eventos inesperados, que pueden ser causados por bugs de programación, interacciones con un ambiente poco cooperativo, mal funcionamiento de hardware, etcétera.

Se pueden encontrar ejemplos de sistemas tolerantes a fallas en casi cualquier parte: protocolos de comunicación, circuitos de hardware, sistemas aviónicas, cripto-monedas, etcétera.

Por lo tanto, el incremento en la relevancia del software crítico en la vida cotidiana ha llevado a que se renueve el interés en la verificación automática de propiedades de tolerancia a fallas. Sin embargo, una de las dificultades principales a la hora de razonar sobre estos tipos de propiedades se da en su naturaleza cuantitativa, lo cual vale incluso en sistemas no probabilistas.
Un ejemplo simple se da con la introducción de redundancia en sistemas críticos. Esta es, sin lugar a dudas, una de las técnicas más utilizadas en tolerancia a fallas.
En la práctica, se sabe que al añadir más redundancia en un sistema incrementa su fiabilidad. Medir este incremento de fiabilidad es un problema central a la hora de evaluar software tolerante a fallas. Por otro lado, no hay un método \emph{de-facto} para caracterizar formalmente propiedades tolerantes a fallas, y por ello se suelen codificar utilizando mecanismos \emph{ad-hoc} como parte del diseño general.

Usualmente el flujo del diseño y verificación de sistemas tolerantes a fallas consiste en definir un modelo nominal (i.e. el programa ``sin fallas'' o ``ideal'') y luego extenderlo con comportamientos defectuosos que se desvían del comportamiento normal prescrito por el modelo nominal.

Este modelo extendido representa la manera en la que el sistema opera bajo la ocurrencia de fallas.
Hay diferentes maneras de extender el modelo nominal, el enfoque típico involucra la \emph{inyección de fallas}  \cite{HsuehTI97,IyerNGK10}, es decir, la introducción automática de fallas en el modelo. Una propiedad importante que cualquier modelo extendido debería satisfacer es la preservación del comportamiento normal ante la ausencia de fallas.

En \cite{DemasiCMA17} se propone un enfoque formal alternativo para tratar con el análisis de la tolerancia a fallas. Este enfoque permite un análisis totalmente automático y distingue apropiadamente comportamientos defectuosos y normales. Además, este framework es sensible a la inyección de fallas. En ese trabajo se definen tres nociones de relaciones de simulación para caracterizar diferentes tipos de tolerancia a fallas:
tolerancia \emph{masking}, \emph{nonmasking}, y \emph{failsafe}, originalmente definidas en \cite{Gartner99}. 

    Por otro lado, en los últimos años, se ha logrando un progreso significativo en pos de definir métricas o distancias apropiadas para diversos tipos de modelos cuantitativos, incluyendo sistemas de tiempo real \cite{HenzingerMP05}, modelos probabilistas \cite{DesharnaisGJP04}, y métricas para sistemas lineales y ramificados \cite{CernyHR12,AlfaroFS09,Henzinger13,LarsenFT11,ThraneFL10}. 

Algunos autores han resaltado que estas métricas pueden ser útiles para razonar sobre la robustez de un sistema, un concepto relacionado con la tolerancia a fallas. Particularmente, en \cite{CernyHR12}, la noción tradicional de relación de simulación se generaliza, y se introducen tres distancias de simulación entre sistemas, concretamente \emph{correctitud}, \emph{cobertura}, y \emph{robustez}.
A estas distancias se las define utilizando juegos cuantitativos con objetivos \emph{discounted-sum} y \emph{mean-payoff}.
%In this article\footnote{This is a revised and expanded version of a conference paper presented at TACAS 2019 \cite{CastroDDP18b}. A detailed description of the extension is given in Section  \ref{sec:related_work}.}, 
En \cite{CastroDDP18b} introducimos una noción de distancia de tolerancia a fallas entre LTS's. Intuitivamente, esta distancia mide el grado de tolerancia a fallas exhibido por un sistema candidato. Como fue mencionado anteriormente, existen varios niveles de tolerancia a fallas, aquí nos restringimos al análisis de \emph{masking-tolerancia a fallas} ya que usualmente se la considera como el tipo de tolerancia mas benigno y por lo tanto es una propiedad altamente deseable en cualquier sistema critico.
%\cite{}.  %% ADD REFERENCE

A grandes rasgos, un sistema es masking-tolerante a fallas cuando es capaz de enmascarar completamente las fallas, no permitiendo que las mismas tengan consecuencias observables para los usuarios. Formalmente, el sistema debe preservar tanto las propiedades de safety como las de liveness del modelo nominal \cite{Gartner99}. A diferencia de la distancia de robustez definida en \cite{CernyHR12}, la cual mide cuantos errores inesperados son tolerados por una implementación, aquí consideramos una colección especifica de fallas dadas en la implementación y medimos cuantas fallas son toleradas por la implementación de tal manera que puedan ser enmascaradas por los estados del sistema.

También requerimos que el comportamiento normal de la especificación se preserve en la implementación cuando no hay fallas. %Otherwise, the distance is $1$.
Formalmente, dado un sistema nominal $N$ y su implementación $I$ y sea $\delta$ nuestra función de distancia, tenemos que $\DeltaMask(N,I)=1$ si y solo si el modelo nominal $N$ y $I\backslash F$ no son bisimilares, donde $I\backslash F$ se comporta como la implementación $I$ cuando todas las acciones en $F$ están deshabilitadas ($\backslash$ es el operador de restricción de  Milner).
Por lo tanto, distinguimos efectivamente entre el modelo nominal, su versión tolerante a fallas  y el conjunto de fallas para el sistema en cuestión.

Para poder medir el grado de masking-tolerancia a fallas de un sistema dado, empezamos caracterizando la masking-tolerancia a fallas por medio de relaciones de simulación entre dos sistemas, como se define en \cite{DemasiCMA17}. El primero cumple el rol de especificación del comportamiento deseado (i.e el modelo nominal) y el segundo tiene el rol de implementación tolerante a fallas (i.e. el modelo extendido con fallas y mecanismos de tolerancia).
La existencia de una relación de masking implica que la implementación enmascara las fallas. Luego, introducimos una caracterización de la simulacion de masking en términos de juegos y enriquecemos los mismos con objetivos cuantitativos para definir así la noción de \emph{distancia de masking-tolerancia a fallas}, donde los valores posibles del juego pertenecen al intervalo  $[0,1]$. La implementación tolerante a fallas es masking-tolerante a fallas si el valor del juego es $0$. Además, mientras mayor el valor, mas lejos esta la implementación de la especificación en términos de la distancia de masking-tolerancia a fallas. De esta forma, una distancia mayor decrementa notablemente el grado de tolerancia a fallas.

Entonces, para un modelo nominal $N$ y dos implementaciones tolerantes a fallas diferentes $I_1$ y $I_2$, nuestra distancia asegura que  $\DeltaMask(N,I_1)<\DeltaMask(N,I_2)$ cuando $I_1$ tolera mas fallas que $I_2$.

También proporcionamos una versión débil de la simulación de masking, la cual hace posible tratar con sistemas mas complejos compuestos por varios componentes que interactúan entre si. Probamos que la distancia de masking es una semi-métrica dirigida, es decir, que satisface dos propiedades básicas de cualquier distancia: reflexividad y la desigualdad triangular.

Finalmente, hemos implementado nuestra técnica en una herramienta que toma como argumentos un modelo nominal y su implementación tolerante a fallas, y computa automáticamente la distancia de masking entre estos.
Hemos utilizado esta herramienta para medir la tolerancia de masking en múltiples instancias de varios casos de estudio: una celda de memoria redundante, una variación del problema de los filósofos comensales, el protocolo de comunicación BRP (Bounded Retransmission Protocol), redundancia N-Modular, el problema de los generales bizantinos y un subproblema del protocolo de consenso Raft para lograr una replicación consistente de datos.

Todos los casos de estudio mencionados son ejemplos típicos de sistemas tolerantes a fallas. Un punto interesante sobre nuestra implementación es que, para sistemas deterministas, la distancia de masking entre dos sistemas puede ser computada recurriendo a un algoritmo de camino mas corto. Mientras que en el caso de sistemas no deterministas, se aplica un algoritmo de punto fijo basado en la búsqueda a lo ancho (breadth first search), lo cual es menos eficiente, sin embargo en ambos casos el algoritmo es polinomial.


%The remainder of the paper is structured as follows. 
%In Section \ref{sec:background}, we introduce preliminaries notions used 
%throughout this paper.
%We present in Section \ref{sec:masking_dist} the definition of strong (resp. weak) masking simulation 
%and the corresponding game characterization. 
%In Section \ref{sec:QuantMask}, we present the formal definition 
%of masking distance built on quantitative simulation games, the algorithms 
%to compute it, and we also prove its basic properties. 
%We describe in Section \ref{sec:experimental_eval} the experimental 
%evaluation on some well-known case studies.
%In Section \ref{sec:related_work} we discuss the related work. 
%Finally, we discuss in Section \ref{sec:conclusions} some conclusions 
%and directions for further work.
%
%Full details and proofs can be found in \cite{CastroDDP18}.


\section{Preliminares} \label{sec:background}

Vamos a introducir algunas definiciones y resultados básicos sobre teoría de juegos que serán necesarios a lo largo del articulo, el lector interesado puede ver \cite{AptG11}.

Un sistema de transición etiquetado (o TS) es una tupla $A =\langle S, \Sigma, \rightarrow, \InitState \rangle$, donde $S$ es un conjunto finito de estados, $\Sigma$ es un alfabeto finito,  $\rightarrow \subseteq S \times \Sigma \times S$ es un conjunto de transiciones etiquetadas, y $s_0$ es el estado inicial. A partir de ahora, denotaremos $s \xrightarrow{e} s'$ en lugar de $(s,e,s') \in \rightarrow$ cuando creamos conveniente.

Con $|S|$ y $|{\rightarrow}|$ denotamos la cantidad de estados y arcos, respectivamente. Definimos $\post(s) = \{s' \in S \mid s \xrightarrow{e} s' \}$ como el conjunto de sucesores de $s$. Similarmente,  $\pre(s') = \{s \in S \mid s \xrightarrow{e} s' \}$ denota el conjunto de predecesores de $s'$.
Además, $\post^{*}(s)$ denota los estados alcanzables desde $s$.
Sin perder generalidad, requerimos que todo estado $s$ tenga un sucesor, i.e., $\forall s \in S : \post(s) \neq \emptyset$. Decimos que un TS es \emph{determinista} si, para toda terna de estados  $s,t, t'$ y para toda etiqueta $e$, $s \xrightarrow{e} t$ y $s \xrightarrow{e} t'$ implica $t=t'$. 

Una \emph{corrida} en un sistema de transición de estados $A$ es un camino infinito $\rho = \rho_0 \sigma_0 \rho_1 \sigma_1  \rho_2 \sigma_2 \dots \in (S \cdot \Sigma)^{w}$ 
donde $\rho_0 = \InitState$ y para todo $i$, $\rho_i \xrightarrow{\sigma_i} \rho_{i+1}$. De ahora en mas, dada una tupla $(x_0,\dots,x_n)$, denotaremos a $x_i$ con  $\pr{i}{x_0,\dots,x_n}$.

Un \emph{grafo de juego} $G$ es una tupla $G = \langle V, V_1, V_2, E, \InitVertex \rangle$ donde $V$ es un conjunto de vértices, $E\subseteq V \times V$ es un conjunto de arcos, $\InitVertex$ es el vértice inicial del juego, y $(V_1, V_2)$ es una partición de $V$. Intuitivamente, el grafo representa un juego entre dos jugadores, donde un token se coloca inicialmente en el vértice inicial, y luego sigue por rondas. Si el token esta en un vértice $v \in V_1$, entonces el jugador $1$ elige un arco $(v, w) \in E$ y mueve el token al vértice $w$. En caso de que el token este en un vértice $v \in V_2$, entonces la elección es del jugador $2$.

Un \emph{grafo de juego con costos} es un grafo de juego mas una función de costo (o recompensa) $\reward^G:V \rightarrow \mathbb{R}$. Un camino maximal en el grafo de juego $G$ se denomina una \emph{jugada}. El conjunto de todas las jugadas se denota con $\Omega$. Los \emph{grafos de juego deterministas} se definen de la misma manera que en sistemas de transición de estados. Además, utilizaremos la notación $\post(v)$ para denotar los sucesores del vértice $v$, y $\pre(v)$ para denotar a los predecesores del vértice $v$.

Dado un grafo de juego $G$, una \emph{estrategia} para el jugador $1$ es una función $\pi: V^{*} V_1 \rightarrow V$ tal que para todo  $\rho_0  \rho_1 \dots \rho_i \in V^{*} V_1$, tenemos que si $\pi(\rho_0  \rho_1\dots \rho_i) = \rho $, entonces $(\rho_i, \rho) \in E$. Una estrategia para el jugador $2$ se define similarmente. El conjunto de todas las estrategias para el jugador $p$ (para $p \in \{1,2\}$) se denota por $\Pi_{p}$.
Una estrategia para el jugador $p$ se dice \emph{sin memoria} (o posicional) si puede ser definida por un mapping $f:V_p \rightarrow V$, de tal forma que si $v \in V_p$ entonces $(v, f(v)) \in E$.
A grandes rasgos, estas estrategias no necesitan memoria del historial de movimientos. Además, una jugada $\rho_0 \rho_1 \rho_2 \dots$ se conforma a una estrategia $\pi$ del jugador $p$ si $\forall i \geq 0: (\rho_i \in V_p) \Rightarrow  \pi(\rho_0 \rho_1 \dots \rho_i) = \rho_{i+1}$. El \emph{resultado} de una estrategia $\pi_{1}$ del jugador $1$ y una estrategia $\pi_{2}$ del jugador $2$ es la jugada única, denominada $\out(\pi_1, \pi_2)$, que se conforma tanto a $\pi_1$ como a $\pi_2$.

Un \emph{juego} se compone de un grafo de juego y un objetivo booleano o cuantitativo. Un \emph{objetivo booleano} es una función $\Phi: \Omega \rightarrow \{0, 1\}$ y la meta del jugador $1$ en un juego con un objetivo $\Phi$ es seleccionar una estrategia de tal forma que el resultado del juego sea $1$, independientemente de lo que haga el jugador $2$. Por el contrario, la meta del jugador $2$ es asegurarse que el resultado sea $0$. Dado un objetivo booleano $\Phi$, una jugada $\rho$ es \emph{ganadora} para el jugador $1$ (resp. jugador $2$) si  $\Phi(\rho) = 1$ (resp. $\Phi(\rho) = 0$). Una estrategia $\pi$ es una \emph{estrategia ganadora} para el jugador $p$ si toda jugada que se conforme a $\pi$ es ganadora para el jugador $p$. Decimos que un juego con objetivo booleano esta \emph{determinado} si algún jugador tiene una estrategia ganadora, y decimos que está \emph{determinado sin memoria} si esa estrategia ganadora es sin memoria. Los juegos de alcanzabilidad son aquellos juegos cuyos objetivos están definidos como $\Phi(\rho_0 \rho_1 \rho_2 \dots) = (\exists i : \rho_i \in B)$ para algún conjunto $B \subseteq V$, un resultado estándar de los juegos de alcanzabilidad es que son determinados sin memoria.

Un \emph{objetivo cuantitativo} esta dado por una función de \emph{payoff} $f: \Omega \rightarrow \mathbb{R}$ y la meta del jugador $1$ es maximizar el valor $f$ de la jugada, mientras que la meta del jugador $2$ es minimizar este valor. Para un objetivo cuantitativo $f$, el valor del juego para la estrategia $\pi_1$ del jugador $1$, denotado por $v_1(\pi_1)$, se define como el ínfimo sobre todos los valores resultantes de estrategias del jugador $2$, i.e., $v_1(\pi_1) = \inf_{\pi_2 \in \Pi_2} f(\out(\pi_1, \pi_2))$. El valor del juego para el jugador $1$ se define como el supremo de los valores de todas las estrategias del jugador $1$, i.e., $\sup_{\pi_1 \in \Pi_1} v_1(\pi_1)$. Análogamente, el valor del juego para una estrategia $\pi_2$ del jugador $2$ y el valor del juego para el jugador $2$ se definen como $v_2(\pi_2) = \Sup_{\pi_1 \in \Pi_1} f(\out(\pi_1, \pi_2))$ 
y $\inf_{\pi_2 \in \Pi_2} v_2(\pi_2)$, respectivamente.
Una estrategia es \emph{optimal} para un jugador si el valor de la estrategia para ese jugador es igual al valor del juego para ese jugador. Decimos que un juego esta determinado si los valores del juego para ambos jugadores es igual, es decir:
$\sup_{\pi_1 \in \Pi_1} v_1(\pi_1) = \inf_{\pi_2 \in \Pi_2} v_2(\pi_2)$. En este caso denotamos con $\val(\mathcal{G})$ al valor del juego $\mathcal{G}$.
    El siguiente resultado de \cite{Martin98} caracteriza un conjunto grande de juegos determinados.
    \begin{thm} Cualquier juego con una función cuantitativa $f$ que esté acotada y sea Borel-medible esta determinado.
\end{thm}


\section{Simulación de Masking} \label{sec:masking_dist}
Empezamos definiendo la simulación de masking. En \cite{DemasiCMA17}, se definió una simulación basada en estados para la masking-tolerancia a fallas, aquí reutilizamos esta definición usando sistemas de transición etiquetados. Primero, vamos a introducir algunos conceptos que son necesarios para definir masking-tolerancia a fallas. Para todo vocabulario $\Sigma$, y todo conjunto de etiquetas $\Faults = \{F_0, \dots, F_n\}$ no pertenecientes a $\Sigma$, consideramos 
$\SigmaF = \Sigma \cup \Faults$, donde $\Faults \cap \Sigma = \emptyset$. Intuitivamente, los elementos de $\Faults$ indican la ocurrencia de una falla en una implementación defectuosa. Además, a veces sera útil considerar el conjunto $\Sigma^i = \{ e^i \mid e \in \Sigma\}$, que contiene los elementos de $\Sigma$ indexados con el superíndice $i$.

%, $\Sigma^i = \{\sigma^i \mid \sigma \in \Sigma\}$.

\subsection{Simulación de Masking fuerte}
\begin{defi} \label{def:masking_rel}
  Sean $A =\langle S, \Sigma, \rightarrow, s_0\rangle$ y $A' =\langle S', \SigmaF, \rightarrow', s_0' \rangle$ dos sistemas de transición etiquetados.
  $A'$ es \emph{fuertemente masking-tolerante a fallas} con respecto a $A$ si existe una relación 
$\M \subseteq S \times S'$ entre $A$ y $A'$ tal que:

\begin{enumerate}[(A)]
  \item $s_0 \M s'_0$, y
  \item para todo $s \in S, s' \in S'$ con $s \M s'$ y todo $e \in \Sigma$ vale lo siguiente:

  \begin{enumerate}[(1)]
    \item 
    si $s \xrightarrow{e} t$ entonces
    $\exists\; t' \in S': s' \xrightarrowprime{e} t'  \wedge t \M t'$;

      \item si $s' \xrightarrowprime{e} t'$ entonces
      $\exists \; t \in S: s \xrightarrow{e} t \wedge t \M t'$;

      \item si $s' \xrightarrowprime{F} t' $ para algún $F \in \Faults$ entonces
      $s \M t'$.
      
  \end{enumerate}
\end{enumerate}

Si tal relación existe decimos que $A'$ es una \emph{implementación fuertemente masking-tolerante a fallas} de $A$, denotado como $A \Masking A'$. 
\end{defi}

 Intuitivamente, la definición establece que, partiendo de $s'$, las fallas pueden ser enmascaradas de tal forma que el comportamiento exhibido es el mismo que el observado al partir de $s$ ejecutando transiciones sin fallas. 
 En otras palabras, una relación de masking asegura que cualquier comportamiento defectuoso en la implementación puede ser simulado por la especificación. Mas específicamente, note que las condiciones (A), (B.1) y (B.2) implican que tenemos una bisimulación cuando $A$ y $A'$ no exhiben comportamientos defectuosos.
Particularmente, la condición (B.1) dice que la ejecución normal de $A$ puede ser simulada por una ejecución de $A'$. Por otro lado, la condición (B.2) dice que la implementación no agrega mas comportamientos normales (no defectuosos). Por ultimo, la condición (B.3) establece que toda transición defectuosa ($F$) que salga de $s'$ debe ser emparejada por un movimiento en el mismo lugar desde $s$.

\subsection{Simulación de Masking Débil}

Para analizar sistemas no triviales se necesita una relación de simulación de masking débil. La idea principal es que una simulación de masking débil se abstrae del comportamiento interno, el cual es modelado por una acción especial $\tau$. Note que las transiciones internas son comunes en tolerancia a fallas: las acciones ejecutadas como parte de un procedimiento tolerante a fallas en un componente usualmente no son observables para el resto del sistema.

Las \textit{relaciones de transición débiles} ${\Rightarrow} \subseteq S
\times (\Sigma \cup \{\tau\} \cup \Faults) \times S$ consideran el paso \emph{silencioso} $\tau$ que se define como sigue: 

\[
\xRightarrow{e} = 
       \begin{cases}
            \xrightarrowstar{\tau} \circ \xrightarrow{e} \circ \xrightarrowstar{\tau} & 
            \text{si } e \in \Sigma,  \\ 
            \xrightarrowstar{e} & \text{si } e = \tau,  \\
            \xrightarrow{e} & \text{si } e \in \Faults.\\
       \end{cases}
\]
%
El símbolo $\circ$ representa la composición de relaciones binarias y $\xrightarrowstar{\tau}$ es la clausura reflexo-transitiva de la relación binaria $\xrightarrow{\tau}$. 

Intuitivamente, si $e \notin \{\tau\}\cup\Faults$, entonces $s\xRightarrow{e}s'$ significa que existe una secuencia de cero o mas transiciones $\tau$ empezando en $s$, seguido de una transición etiquetada por $e$, seguida luego por cero o mas transiciones $\tau$ eventualmente llegando a  $s'$.
$s \xRightarrow{\tau} s'$ establece que $s$ puede transicionar a $s'$ por medio de cero o mas transiciones $\tau$.
%
En particular, $s \xRightarrow{\tau} s$ para todo $s$.
%
Para el caso en que $e\in\Faults$,
$s\xRightarrow{e}s'$ es equivalente a $s\xrightarrow{e}s'$ y por lo tanto
no se permite ningún paso $\tau$ antes o después de la transición $e$.


\begin{defi} \label{def:weak_mask}
  Sean $A =\langle S, \Sigma, \rightarrow, \InitState \rangle$ y $A' =\langle S',
  \SigmaF, \rightarrow', \InitStatePrime \rangle$ dos sistemas de transición etiquetados con $\Sigma$
  conteniendo $\tau$ posiblemente.  $A'$ es \emph{débilmente masking-tolerante a fallas}
  con respecto a $A$ si existe una relación $\M \subseteq S
  \times S'$ entre $A$ y $A'$ tal que:

\begin{enumerate}[(A)]
  \item $\InitState \M \InitStatePrime$
  \item para todo $s \in S, s' \in S'$ con $s \M s'$ y todo $e \in \Sigma \cup \{\tau\}$ vale lo siguiente:

  \begin{enumerate}[(1)]
    \item si $s \xrightarrow{e} t$ entonces 
    $\exists\; t' \in S': s' \xRightarrowprime{e} t' 
    \wedge t \M t'$;

      \item si $s' \xrightarrowprime{e} t'$ entonces  
      $\exists \; t \in S: s \xRightarrow{e} t  
      \wedge t \M t'$;

      \item si $s' \xrightarrowprime{F} t'$ para algún $F \in \Faults$ entonces 
      $s \M t'$.
  \end{enumerate}
\end{enumerate}

%
Si tal relación existe, decimos que $A'$ es una \emph{implementación débilmente masking-tolerante a fallas} de
$A$, denotado por $A \WeakMasking A'$.
\end{defi}

El siguiente teorema conecta la simulación de masking fuerte y débil. El teorema establece que la simulación de masking débil se vuelve una simulación de masking fuerte cuando la transición $\xrightarrow{}$ es reemplazada por $\xRightarrow{}$ en la estructura original.

\begin{thm} \label{thm:weak_thm}
  Sean
$A =\langle S, \Sigma, \rightarrow, \InitState \rangle$ y $A' =\langle S', \SigmaF, \rightarrow', \InitStatePrime \rangle$. 
$\M \subseteq S \times S'$ entre $A$ y $A'$ es una simulación de masking débil si y solo si:

\begin{enumerate}[(A)]
  \item $\InitState \M \InitStatePrime$, y
  \item para todo $s \in S, s' \in S'$ con $s \M s'$ y todo $e \in \Sigma \cup \{\tau\}$ vale lo siguiente:

  \begin{enumerate}[(1)]
    \item si $s \xRightarrow{e} t$ entonces $\exists\; t' \in S': s' \xRightarrowprime{\text{e}} t' 
    \wedge t \M t'$;

      \item si $s' \xRightarrowprime{e} t'$ entonces 
      $\exists \; t \in S: s \xRightarrow{e} t \
      \wedge t \M t')$;

      \item si $s' \xRightarrowprime{F} t'$ para algún $F \in \Faults$ entonces 
      $s \M t'$
  \end{enumerate}
\end{enumerate}

\end{thm}

\noindent
\begin{proof}
	Primero note que las condiciones (A), (B.1), (B.2) y (B.3) en este teorema implican las condiciones (A), (B.1), (B.2) y (B.3)
 de la Def.~\ref{def:weak_mask}, entonces la parte ``si'' es directa. Para la otra dirección, la condición (A) es la misma en el teorema y en la definición.
 Supongamos ahora que la condición (B.1) de la Def.~\ref{def:weak_mask} vale, i.e.,
 $s \xRightarrow{e} t$ para $e \in \Sigma \cup \{\tau\}$ y $t \in S$. 
Si $e \in \Sigma$, entonces, por definición de$\Rightarrow$, tenemos que existen $w$ y $v$ tal que $s \xrightarrowstar{\tau} w$, $w \xrightarrow{e} v$
 y $v \xrightarrowstar{\tau} t$. Por lo tanto, por definición de $\Rightarrow$ y por la condición (B.2) de la Def. \ref{def:weak_mask} 
 tenemos que existen estados $s',t',w',v' \in S'$
 tales que $s' \xRightarrow{\tau} w'$, $w' \xRightarrow{e} v'$, y $v' \xRightarrow{\tau} t'$ y, 
 además, $w \M w'$, $v \M v'$, y $t \M t'$ lo cual implica que$s' \xRightarrow{e} t'$. 
 La prueba para la condición (B.2) es similar.
 	Supongamos ahora que $s \M s'$ y $s' \xRightarrow{F} t'$, para algún $t' \in S'$. Entonces, por Def. de 
$\Rightarrow$, tenemos que $s' \xrightarrow{F} t'$ y por Def.~\ref{def:weak_mask}
 tenemos $s \M t'$ . Esto concluye la prueba.
 \qedhere 
 \end{proof} 
 
Una forma natural de verificar bisimilitud débil es por medio de \emph{saturar}
el sistema de transición  \cite{FernandezM91,Milner89} y lucho verificar bisimilitud fuerte sobre el sistema de transición saturado.
Similarmente, el Theorem~\ref{thm:weak_thm} nos permite computar la simulación de masking débil al reducir este problema a simulación de masking fuerte. Note que $\xRightarrow{e}$ puede ser alternativamente definida por medio de las siguientes reglas:

\[
\dfrac{p \xrightarrow{e} q}{p\xRightarrow{e} q} \hspace{2cm} 
\dfrac{}{p\xRightarrow{\tau} p} \hspace{2cm} 
\dfrac{p\xRightarrow{\tau} p_1 \xRightarrow{e} q_1 \xRightarrow{\tau} q}{p\xRightarrow{e} q}~(e \notin \Faults)
\]
	En lo que sigue utilizamos el teorema \ref{thm:weak_thm} para probar propiedades de masking débil, vale la pena recalcar que la mayoría de propiedades de masking fuerte pueden ser también probadas para masking débil recurriendo a este resultado.
	
\begin{exa}
Consideremos el siguiente ejemplo, consideramos una celda de memoria que almacena un bit de información y soporta operaciones de lectura y escritura, presentado en forma basada en estados en \cite{DemasiCMA17}. Un estado en este sistema mantiene el valor corriente de la celda de memoria ($m=i$, para $i=0,1$), escribir le permite a uno cambiar este valor, y leer retorna el valor almacenado.  
Obviamente, en este sistema el resultado de una lectura va a depender del valor almacenado en la celda. 
Por lo tanto, una propiedad que uno podría asociar a este modelo es que el valor leído de la celda coincida con el de la ultima escritura que se haya ejecutado en el sistema.
    
Una falla potencial en este escenario ocurre cuando la celda inesperadamente pierde su carga, y su valor almacenado cambia (e.g., cambia de $1$ a $0$ debido a perdida de carga). Una técnica típica para lidiar con esta situación es \emph{redundancia}: usar tres bits de memoria en lugar de solo uno. Las operaciones de escritura se realizan simultáneamente sobre los tres bits. La lectura, por otro lado, retorna el valor que se repite en la mayoría de bits, esto se conoce como \emph{votación}. 

Tomamos el siguiente enfoque para modelar este sistema. Las etiquetas $\text{W}_0, \text{W}_1, \text{R}_0,$ y $\text{R}_1$
representan las operaciones de escritura y lectura. Específicamente, $\text{W}_0$ (resp. $\text{W}_1$): escribe el valor cero (resp. uno) en la celda de memoria. $\text{R}_0$ (resp. $\text{R}_1$): lee el valor cero (resp. uno) almacenado en la celda de memoria.
La figura ~\ref{figure:exam_1_mem_cell} muestra tres sistemas de transición. El primero de izquierda a derecha representa el sistema nominal para este ejemplo (denotado como $A$).
Tanto el segundo como el tercer sistema de transición son implementaciones tolerantes a fallas de $A$, denotados como $A'$ y $A''$ respectivamente. Note que $A'$ contiene una falla, mientras que $A''$ considera dos fallas. Ambas implementaciones usan redundancia triple; intuitivamente, el estado $\text{t}_0$ contiene tres bits con valor cero y $\text{t}_1$ contiene tres bits con valor uno.
Además, el estado $\text{t}_2$ se alcanza cuando uno de los bits cambió de valor ($001$, $010$ o $100$)
En  $A''$, el estado $\text{t}_3$ se alcanza después de que cambia un segundo bit ($011$, $101$ o $110$) empezando del estado $\text{t}_0$.
\begin{figure}[h] 
\begin{center}
    \includegraphics[scale=0.45]{images/example_1_cell_mem.eps} 
   % \vspace{-1cm}
    \caption{Sistemas de transición para la celda de memoria.}
    %\vspace{-0.8cm}
    \label{figure:exam_1_mem_cell}
\end{center}
\end{figure}
\sloppy Es directo de ver que existe una relación de masking'tolerancia a fallas entre $A$ y $A'$, teniendo como testigo la relación $\M = \{(\text{s}_0, \text{t}_0), (\text{s}_1, \text{t}_1), (\text{s}_0, \text{t}_2)\}$. Es sencillo verificar que $\M$ satisface las condiciones de la Def.~\ref{def:masking_rel}.

Por otro lado, no existe una relación de masking entre $A$ y $A''$ ya que el estado $\text{t}_3$ necesita estar relacionado con el estado $\text{s}_0$ en cualquier relación de masking entre estos modelos. Este estado solo puede ser alcanzado con la ejecución de fallas, las cuales son necesariamente enmascaradas por pasos en si mismo. Sin embargo, note que, en el estado $\text{t}_3$, se puede leer el valor $1$ (la transición $\text{t}_3 \xrightarrow{\text{R}_1} \text{t}_3$) mientras que, en el estado $\text{s}_0$, solo se puede leer el valor $0$.
\end{exa}
 
\subsection{Juego de Simulación de Masking} \label{subsec:mask_sim_game}
	Vamos a definir un juego de simulación de masking para dos sistemas de transición (la especificación del sistema nominal y su implementación tolerante a fallas) que captura la masking-tolerancia a fallas. Primero definimos el grafo de juego de masking para dos jugadores, los cuales denominaremos como \emph{Refutador} ($\Refuter$) y \emph{Verificador}
($\Verifier$).

\begin{defi} \label{def:strong_masking_game_graph}
  Sean $A=\langle S, \Sigma, \rightarrow, \InitState \rangle$ y $A'=\langle S',
  \SigmaF, \rightarrow', \InitStatePrime \rangle$ dos sistemas de transición.
  % and $M \notin \Sigma \cup \SigmaF$.
  El \emph{grafo de juego para masking fuerte} 
  $\StrMaskGG = \langle V^G, V_\Refuter, V_\Verifier, E^G, {\InitVertex}^G \rangle$ 
  para dos jugadores se define de la siguiente manera:

\begin{itemize}
    %\item $\Sigma^G = \Sigma^1 \cup \SigmaF^2$
  \item $V^G = (S \times ( \Sigma^1 \cup \SigmaF^2 \cup\{\#\}) \times S' \times \{ \Refuter, \Verifier \}) 
  \cup \{\ErrorSt\}$
  \item El estado inicial es $\InitVertex^G = \langle \InitState, \#, \InitStatePrime, \Refuter \rangle$, donde el Refutador comienza a jugar.
  \item Los estados del Refutador son $V_\Refuter = \{ (s, \#, s', \Refuter) \mid s \in S \wedge s' \in S' \} 
  \cup \{\ErrorSt\}$
  \item Los estados del Verificador son $V_\Verifier = \{ (s, \sigma, s', \Verifier) \mid s \in S \wedge s' \in S' \wedge \sigma \in ( \Sigma^1 \cup \SigmaF^2 )\}$
\end{itemize}
y $E^G$ es el conjunto minimal que satisface que:
\begin{itemize}
  \item $\{ ( (s, \#, s', \Refuter) , (t, \sigma^{1}, s', \Verifier)) \mid \exists\;\sigma \in \Sigma: s \xrightarrow{\sigma} t \} \subseteq E^G$,

  \item $\{ ((s, \#, s', \Refuter), (s, \sigma^{2}, t', \Verifier))  \mid \exists\;\sigma \in \SigmaF: s' \xrightarrowprime{\sigma} t' \} \subseteq E^G$,

  \item $\{ ((s, \sigma^2, s', \Verifier), (t, \#, s', \Refuter)) \mid \exists\;\sigma \in \Sigma: s \xrightarrow{\sigma} t \} \subseteq E^G$,

  \item $\{ ((s, \sigma^1, s', \Verifier), (s, \#, t', \Refuter)) \mid \exists\;\sigma \in \Sigma: s' \xrightarrowprime{\sigma} t' \} \subseteq E^G$,

  \item $\{ ((s, F^2, s', \Verifier), (s, \#, s', \Refuter)) \} \subseteq E^G$, para cada $F \in \Faults$. 

  \item Si no hay transiciones que salgan de algún estado $v$, entonces, adicionalmente asumimos que $(v, \ErrorSt) \in E^G$ y $(\ErrorSt, \ErrorSt) \in E^G$.
\end{itemize}

\end{defi}

La intuición de este juego es lo siguiente. 
El Refutador elige transiciones de la especificación o de la implementación y hace su movimiento, luego el Verificador trata de igualar el movimiento de su contrincante, esto es similar al juego de bisimulación \cite{Stirling99}. 
Sin embargo, cuando el Refutador escoge una falla (note que solo este jugador puede elegir fallas), el Verificador debe igualar su movimiento con un paso en si mismo.
Esto intuitivamente se puede interpretar como un enmascaramiento de la falla por parte de la implementación tolerante a fallas de tal manera que la falla no puede ser observada del lado del usuario. $\Refuter$ gana si el juego alcanza un estado de error, i.e., $\ErrorSt$; de lo contrario, $\Verifier$ gana el juego. 
Básicamente este juego es un juego de alcanzabilidad \cite{Jurd11}.

Un \emph{grafo de juego de masking débil} $\WeakMaskGG$ se define de la misma manera que su contraparte fuerte de la 
Def.~\ref{def:strong_masking_game_graph}, con la diferencia de que
$\Sigma$ y $\SigmaF$ pueden contener $\tau$, y que el conjunto de transiciones etiquetadas (denotado como $E_W^G$) ahora se define utilizando relaciones de transición débiles (i.e., $\Rightarrow$ y $\Rightarrow'$) de los sistemas de transición respectivos.

La figura ~\ref{figure:exam_2_mem_cell_gg_two_faults} muestra una parte del juego de masking fuerte para el ejemplo que vimos considerando los sistemas de transición $A$ y $A''$. Aquí, los nodos del Refutador están representados gráficamente como cajas mientras que los nodos del Verificador están representados por círculos.
Podemos observar claramente en el grafo de juego que el Verificador no puede imitar la transición $((s_0, \#, t_3, R),(s_0, R_1^2, t_3, V))$
seleccionada por el Refutador, donde lee el valor $1$ en el estado $t_3$ de la implementación tolerante a fallas. Esto se da porque el Verificador solo puede leer el valor $0$ en el estado $s_0$. 
Entonces, el estado $\ErrorSt$ es alcanzado y el Refutador gana.

Como es de esperarse, hay una simulación de masking fuerte entre $A$ y $A'$
si y solo si el Verificador tiene una estrategia ganadora en $\StrMaskGG$.

\begin{thm} \label{thm:wingame_strat}
  Sean $A=\langle S, \Sigma, \rightarrow, \InitState \rangle$ y $A'=\langle S', \SigmaF, \rightarrow', \InitStatePrime \rangle$ dos sistemas de transición.
  Entonces, $A \Masking A'$ si y solo si el Verificador tiene una estrategia ganadora para el grafo de juego de masking fuerte $\StrMaskGG$.
\end{thm}
\begin{proof} 
	``solo si'': Supongamos que existe una simulación de masking $\M \subseteq S \times S'$.
La estrategia del Verificador (denominada $\pi^*$) se construye de la siguiente forma:  para los estados $(t, \sigma^1, s', V)$ (resp. $(s, \sigma^2, t', V)$) tal que el conjunto $\{ z' \in \post(s'): t \M z' \}$
(resp. $\{ z \in \post(s): z \M t' \}$) no es vacío y $\sigma \notin \Faults$, definimos $\pi^*(t, \sigma^1, s', \Verifier) = (t, \#, t', \Refuter)$ 
(resp. $\pi^*(s, \sigma^2, t', \Verifier) = (t, \#, t', \Refuter)$) que se corresponde con el arco $((t, \sigma^1, s', \Verifier), (t, \#, t', \Refuter))$ (resp. $((s, \sigma^2, t', \Verifier),(t, \#, t', \Refuter))$) tal que $t \in \{ z \in \post(s): z \M t' \}$ (resp. $t' \in \{ z' \in \post(s): z' \M t' \}$).  Si $\sigma \in \Faults$, entonces definimos $\pi^*(s, F^2, s', \Verifier) = (s, \#, s', \Refuter)$, para cualquier $F \in \Faults$, correspondiente con el arco $((s, F^2, s', \Verifier),( s, \#, s', \Refuter))$. Si el conjunto $\{ z' \in \post(s'): t \M z' \}$  (resp. $\{ z \in \post(s): z \M t' \}$) 
es vacío devuelve un vértice correspondiente a un arco arbitrario. 

	Probamos que cualquier jugada: $\rho_0 \rho_1 \dots$ (conforme a la estrategia $\pi^*$) cumple con: 
	(1) $\pr{3}{\rho_i}=\Verifier \vee \pr{0}{\rho_i} \Masking \pr{2}{\rho_i}$ y 
	(2) $\rho_i \neq \ErrorSt$, para todo $i\geq 0$. Esto implica que la estrategia es ganadora para el Verificador. 
La prueba es por inducción sobre $i$. El caso base es directo ya que 
$\InitVertex^G \neq \ErrorSt$ y $\InitVertex^G = (\InitState, \#, \InitStatePrime, \Refuter)$ y por suposición tenemos $\InitState \Masking \InitStatePrime$. Para el caso inductivo, asumimos que 
\todo{No entiendo esta frase}
$\rho_i$ holds $\rho_i \neq \ErrorSt$ y que $\pr{3}{\rho_i} = \Verifier$ o $\pr{0}{\rho_i} \Masking \pr{2}{\rho_i}$. 
Si $\rho_i = (s, \#, s', \Refuter)$, entonces esto significa que $s \Masking s'$. Como asumimos que
$\rightarrow$ y $\rightarrow'$ son seriales, tenemos que: $\exists \sigma \in \Sigma: s \xrightarrow{\sigma} t$ y $\exists \sigma \in \SigmaF : s' \xrightarrowprime{\sigma} t'$. Es decir, por definición del juego, $\rho_{i+1} \neq \ErrorSt$. 
Además, $\pr{3}{\rho_{i+1}} = \Verifier$ y entonces las aserciones (1) y (2) valen. 
Si $\rho_i = (s, \sigma^1, t, \Verifier)$ (resp. $\rho_i = (s, \sigma^2, t, \Verifier)$) y $\sigma \notin \Faults$,
tenemos que $\rho_{i-1} = (s, \#, s', \Refuter)$ y tenemos una transición $s \xrightarrow{\sigma} t$ (resp. $s' \xrightarrowprime{\sigma} t'$), por hipótesis inductiva, $s \Masking s'$. 
Por lo tanto, existe una transición $s' \xrightarrowprime{\sigma} t'$ (resp.  $s \xrightarrow{\sigma} t$) tal que $t \Masking t'$. 
La estrategia juega acorde a una de estas transiciones y entonces
$\rho_{i+1} = (t, \#, t', \Refuter)$ y $t \Masking t'$ y también $\rho_{i+1} \neq \ErrorSt$. Si $\sigma \in \Faults$, entonces $\rho_i = (s, F^2, t', \Verifier)$ para algún $F \in \Faults$. 
Por lo tanto, $\rho_{i-1} = (s, \#, s', \Refuter)$ con $s \Masking s'$ (por hipótesis inductiva). Esto significa que hay una transición $s' \xrightarrowprime{F} t'$, y por Def.~\ref{def:masking_rel},
tenemos que $s \Masking t'$. Además, por definición $\pi^*(s, F^2, t', \Verifier) = (s, \#,t',\Refuter)$, 
y además $s \Masking t'$. 

``si'': Supongamos que el Verificador tiene una estrategia ganadora (llamémosla $\pi$) 
desde el estado inicial. Entonces, definimos la relación de simulación de masking de la siguiente manera: 
\[
\M = \{(s,s') \mid \Verifier \text{ tiene una estrategia ganadora para } (s, \#, s', \Refuter) \}.
\]
Vamos a probar que es una simulación de masking. 
Primer, tenemos que $\InitState \M \InitStatePrime$ ya que $\pi$ es ganadora en $\InitVertex^G$. Por la condición (B.1) de la Def.~\ref{def:masking_rel}, si
$s \M s'$ y $s \xrightarrow{\sigma} t$ para algún $s \in S$ y $s' \in S'$, entonces debemos tener que $\pi$ es ganadora para cualquier estado $(s,\#,s',\Refuter)$. Además, por Def.~\ref{def:strong_masking_game_graph} existe un arco 
$((s,\#,s',\Refuter), (t,\sigma^1,s',\Verifier))$. 
Pero como $\pi$ es ganadora, también tenemos que $\pi(t,\sigma^1,s',\Verifier) \neq \ErrorSt$ y 
por lo tanto $\pi(t,\sigma^1,s',\Verifier)=(t, \#, t', \Refuter)$ y $\pi$ es ganadora desde  $(t, \#, t', \Refuter)$.
De este modo, hay una transición $t \xrightarrowprime{\sigma} t'$ tal que
$t \Masking t'$. La prueba para (B.2) es análoga. Para (B.3), asumamos que $s \Masking s'$ y $s' \xrightarrowprime{F} t'$ para algún 
$F \in \Faults$. 
Como antes, desde el estado $(s,\#,s',\Refuter)$, $\pi$ es ganadora donde también tenemos un arco $((s,\#,s',\Refuter), (s,F^2,t',\Verifier))$ por definición del juego. 
Como $\pi$ es ganadora desde $(s,\#,s',\Refuter)$ para el Verificador, existe una jugada $\pi(s,F^2,t',\Verifier) = (s,\#,t',\Refuter)$ tal que $\pi$ gana desde 
$(s,\#,t',\Refuter)$. Por lo tanto, $s \Masking t'$, y el resultado se deduce.
\qedhere

\end{proof} \\

Por el teorema ~\ref{thm:weak_thm}, el resultado también vale para juegos de masking débiles lo cual esta establecido en el siguiente teorema.

\begin{thm} \label{thm:weak_wingame_strat}
  Sean $A=\langle S, \Sigma \cup \{\tau\}, \rightarrow, \InitState \rangle$ y
  $A'=\langle S', \SigmaF \cup \{\tau\}, \rightarrow', \InitStatePrime \rangle$.
  $A \WeakMasking A'$ si y solo si el Verificador tiene una estrategia ganadora para el grafo de juego de masking débil $\WeakMaskGG$.
\end{thm}

\begin{thm}\label{th:game-determined}
  Para cualquier $A$ y $A'$, el grafo de juego de masking fuerte (resp.\ débil) 
  $\StrMaskGG$ (resp.\ $\WeakMaskGG$) puede ser determinado en tiempo $\BigO(|E^G|)$ (resp.\ $\BigO(|E_W^G|)$).
\end{thm}
\begin{proof}
	El conjunto de estados ganadores para el Refutador puede ser computado utilizando una búsqueda primero en ancho de abajo hacia arriba(bottom-up breadth-first) desde el estado de error, como en juegos de alcanzabilidad \cite{Jurd11}. 
Este procedimiento inspecciona cada arco, en el peor caso. Esto significa que el tiempo de ejecución de este algoritmo es $\BigO(|E^G|)$ para el caso de masking fuerte, y $\BigO(|E_W^G|)$ para el caso débil. Para este ultimo caso, hay que tener en cuenta que computar  
$\Rightarrow$ a partir de $\rightarrow$ toma un tiempo polinomial.
\qedhere
\end{proof} \\
\begin{figure} [h]
\begin{center}
    %\vspace{-0.5cm}
   % \includegraphics[scale=0.5]{ex1_cell_mem_game_graph_two_faults.eps} 
    \includegraphics[scale=0.5]{images/ex1_cell_mem_game_graph_two_faults.eps} 
  %  \vspace{-0.7cm}
    \caption{Parte del grafo de juego de masking para la celda de memoria con dos fallas}
    \label{figure:exam_2_mem_cell_gg_two_faults}
     %\vspace{-0.6cm}
\end{center}
\end{figure}

	Se puede solucionar juegos de alcanzabilidad computando conjuntos $\text{Reach}_0$ (estados ganadores para el Refutador) como un punto fijo de conjuntos $\text{Reach}^i_0$  \cite{Jurd11}.
	Estas ideas pueden ser adaptadas a nuestro contexto para tener en cuenta la cantidad de fallas. Esto sera útil en las próximas secciones, donde la cantidad de fallas es importante para razonar sobre la versión cuantitativa de los juegos de masking.
\begin{defi}\label{def:U} Dado un grafo de juego de masking fuerte $\StrMaskGG$, 
los conjuntos $\setsUs$ (para $i,j \geq 0$) se definen de la siguiente manera:
\begin{align*}
  U^0_i =& U^j_0 = \emptyset,  \label{def:of:Uji} \\
  U_1^1 =&  \{\ErrorSt\},
  \hspace{12.5cm} {}\notag
\end{align*}
%\vspace{-0.8cm}
\begin{align*}
  U_{i+1}^{j+1} =&
    \{v' \mid v' \in V_\Refuter \wedge \post(v') \cap U_{i+1}^j \neq \emptyset\} \\
    &\textstyle\cup
    %\{v' \mid v' \in S_V \wedge post(v') \subseteq \bigcup_{j'\leq j} U_{i+1}^{j'} \wedge post(v') \cap U^j_{i+1} \neq \emptyset \wedge \pr{2}{v'} \notin \Faults \} \\
    %NOTE: above is the original condition of TACAS paper
    \{v' \mid v' \in V_\Verifier \wedge \post(v') \subseteq \bigcup_{i'\leq i+1, j' \leq j}U_{i'}^{j'} \wedge \post(v') \cap U^j_{i+1} \neq \emptyset \wedge \pr{1}{v'} \notin \Faults \} \\
    &\textstyle \cup
    \{v' \mid  v' \in V_\Verifier \wedge \post(v') \subseteq \bigcup_{i'\leq i, j' \leq j}U_{i'}^{j'} \wedge \post(v') \cap \setsUs \neq \emptyset \wedge \pr{1}{v'} \in \Faults \}
\end{align*}
Además, $U^k = \bigcup_{i \geq 0} U_i^k$ y $U = \bigcup_{k \geq 0} U^k$.
\end{defi}
Intuitivamente, el subíndice $i$ en $U^k_i$ indica que $\ErrorSt$ es alcanzado después de que hayan ocurrido a lo sumo $i-1$ fallas y $k$ pasos.
El siguiente lema se demuestra de forma directa utilizando técnicas estándar de juegos de alcanzabilidad \cite{AlfaroHK07}.
	Note que estos conjuntos también pueden ser computados para juegos débiles de forma similar utilizando la relación $\Rightarrow$.
\begin{lem} \label{lemma:RefWinStrat} El Refutador tiene una estrategia ganadora en $\mathcal{G}_{A, A'}$ (o $\mathcal{G}^W_{A, A'}$) si y solo si $\InitVertex^G \in U^k$, para algún $k$.
\end{lem}
\begin{proof} 
	``solo si'': La prueba utiliza resultados estándar de juegos de alcanzabilidad. Mas específicamente, considere el conjunto $V^G \setminus U$, este conjunto es una trampa para el Refutador, es decir, si $(s,\sigma, s', \Verifier) \in V^G \setminus U$, entonces existe un $v \in \post((s,\sigma, s', \Verifier))$ tal que 
$v \in V^G \setminus U$, sino
$(s,\sigma, s', \Verifier) \in U^k$ para algún $k$. Similarmente, si $(s,\#, s', R) \in V^G \setminus U$, entonces para todo $v \in \post((s,\#, s', \Refuter))$ 
tenemos $v \in V^G \setminus U$. Esto significa que $V^G \setminus U$ es una ``trampa'' para el Refutador. 
Ahora bien, podemos definir una estrategia para el Verificador $\pi_\Verifier$ de la siguiente manera: si $(s, \sigma, s', \Verifier) \in V^G \setminus U$, entonces
$\pi_\Verifier(s, \sigma, s', \Verifier) = \rho$ para algún $v \in V^G \setminus U$ el (cuya existencia esta garantizada), de lo contrario retorna un nodo arbitrario. 
Esta estrategia es ganadora para el Verificador desde cualquier $v \in V^G$, es decir, para cualquier jugada $\rho_0 \rho_1 \rho_2 \dots$ 
si $\rho_0 \in V^G \setminus U$, entonces $\forall i \geq 0: \rho_i \in V^G \setminus U$ 
(lo cual implica que $\forall i \geq 0: \rho_i \neq \ErrorSt$). 
La prueba es por inducción sobre $i$. Para $i=0$ el resultado es directo ya que $\rho_0 \in V^G \setminus \{\ErrorSt\}$. Para el caso inductivo,
supongamos que $\rho_i \in V^G \setminus U$. En el caso de que $\rho_i = (s, \sigma, s', \Verifier)$, entonces por definición de $\pi_\Verifier$, 
$\rho_{i+1} = \pi_\Verifier(s,\sigma, s', \Verifier) \in V^G \setminus U$.
Además, si $\rho_i = (s, \#, s', \Refuter)$, entonces $\post((s, \#, s', \Refuter)) \subseteq V^G \setminus U$, 
y por lo tanto $\rho_{i+1} \notin U$. 
Ahora bien, como $\InitVertex^G \notin U^k$ para todo $k$, entonces $\InitVertex^G \notin U$ y $\InitVertex^G \in V^G \setminus U$. 
En consecuencia, por la propiedad demostrada arriba $\Refuter$ tiene una estrategia ganadora desde 
$\InitVertex^G$. Pero esto es una contradicción porque el Refutador y el Verificador no pueden tener ambos estrategias ganadoras desde los mismos estados.
Por consiguiente, $\InitVertex^G \in U^k$ para algún $k$.
	
``si'': Considere $\InitVertex^G \in U^k$ para algún $k$, es decir, tenemos  $\InitVertex^G \in U^k_i$ para algún $i$ por Def.~\ref{def:U}. 
Además, para cada $v \in V^G$ definimos $\delta(v) = \min \{ (i,j) \mid v \in U^j_i \}$ (usando orden lexicográfico), por conveniencia asumimos $\min \emptyset = (\infty, \infty)$.
Entonces, la estrategia ganadora $\pi_R$ para el Refutador se define de la siguiente forma. Si $\delta(v) = (i,j)$ (con $(i,j) < (\infty, \infty)$), entonces $\pi_\Verifier(v) = w$, con $w$ siendo un vértice tal que
$\delta(w) = (i,j-1)$ (si $\pr{1}{v} \notin \Faults$) o $\delta(w) = (i-1,j-1)$ (si $\pr{1}{v} \in \Faults$), cuya existencia esta garantizada por Def.~\ref{def:U}. De otra forma, $\pi_\Refuter(v)$ retorna
un vértice arbitrario. Note que para cualquier jugada $\rho_0 \rho_1 \rho_2 \dots$ comenzando en $\InitVertex^G$ tenemos que:  para todo $i \geq 0$, $\delta(\rho_i) > \delta(\rho_{i+1})$, en orden lexicográfico.
	Por lo tanto, para algún $k>0$ tenemos $\delta(\rho_k) = (1,1)$, y por tanto $\rho_k = \ErrorSt$.
\qedhere
\end{proof} \\

Por el teorema \ref{thm:weak_thm}, esta prueba también aplica al juego de masking débil $\WeakMaskGG$.
%By theorem \ref{thm:weak_thm}, the proof also applies for the weak masking game graph $\mathcal{G}^W_{A, A'}$. 

\section{Masking Cuantitativo} \label{sec:QuantMask}
En esta sección, extendemos el juego de simulación de masking fuerte (resp. débil) introducido anteriormente con objetivos cuantitativos para así definir la noción de distancia de masking-tolerancia a fallas.
% In practice, fault-tolerance appears with a quantitative flavor, that is, fault-tolerant systems have %degrees of tolerance. This is particularly true when techniques like redundancy and voting are used.  %take this into account. 
Es importante remarcar que utilizamos el atributo  ``cuantitativo'' en un sentido no probabilista.
\begin{defi}  
  %Let $A=\langle S, \Sigma, E, s_0\rangle$ and $A'=\langle S', \Sigma_{\Faults}, E', s'_0 \rangle$.  T
  Para los sistemas de transición $A$ y $A'$, el \emph{grafo de juego de masking cuantitativo fuerte} 
  $\QMStrGame = \langle V^G, V_\Refuter, V_\Verifier, E^G,  \InitVertex^G,  \reward^G \rangle$ se define de la siguiente manera:
 
\begin{itemize}
\item
  $\mathcal{G}_{A, A'}=\langle V^G, V_\Refuter, V_\Verifier, E^G, \InitVertex^G \rangle$ se define como en Def.~\ref{def:strong_masking_game_graph},
\item
  $ \reward^G(v) = (\chi_{\Faults}(\pr{1}{v}), \chi_{\ErrorSt}(v))$

\end{itemize}
%
donde $\chi_{\Faults}$ es la función característica sobre el conjunto $\Faults$, devolviendo $1$ si $\sigma \in \Faults$ y $0$ de otro modo, y $\chi_{\ErrorSt}$ es la función característica sobre el singleton $\{\ErrorSt\}$.
\end{defi}
Note que la función de recompensa retorna un par de números en lugar de un solo numero. Es directo codificar al par como un único numero pero no lo hacemos por claridad. Remarcamos que el
\emph{grafo de juego de masking cuantitativo débil} $\QMWeakGame$
se define de la misma forma que el grafo de juego definido arriba pero utilizando el grafo de juego de masking débil $\mathcal{G}^W_{A, A'}$ en lugar de 
$\mathcal{G}_{A, A'}$


Dado un grafo de juego de masking cuantitativo fuerte con la función de recompensa $\reward^G$ y la jugada 
$\rho = \rho_0 \rho_1 \rho_2, \ldots$, para todo $i \geq 0$, sea 
%$v_i = v^G(\rho_i \xrightarrow{\sigma_i} \rho_{i+1})$.
$r_i = \reward^G(\rho_i)$.
Definimos la \emph{función de payoff de masking} de la siguiente manera: 
\[%\displaystyle
\FMask(\rho) = \lim_{n \rightarrow \infty}  \frac{\pr{1}{r_n}}{1+ \sum^{n}_{i=0} \pr{0}{r_i}},
%\FMask(\rho) = \liminf_{n \rightarrow \infty}  \frac{\pr{1}{v_n}}{1+ \sum^{n}_{i=0} \pr{0}{v_i}},
\]
la cual es proporcional a la inversa de la cantidad de movimientos de enmascaramiento realizados por el Verificador. Para entender esto, note que el numerador de $\frac{\pr{1}{r_n}}{1+ \sum^{n}_{i=0} \pr{0}{r_i}}$ será $1$
cuando alcancemos el estado de error, es decir, en aquellos caminos que no alcancen el estado de error esta formula devuelve $0$. Además. si el estado de error es alcanzado,  el denominador contara el numero de transiciones de falla tomadas hasta el estado de error. Todas, a excepción de la ultima fueron enmascaradas exitosamente. Sin embargo, la ultima falla tratara de ser enmascarada por el Verificador, pero eventualmente llevará al estado de error.
Es decir, los vértices con valor $(1,\_)$ son aquellos correspondientes a fallas. Los demás se corresponden con $(0,\_)$.
Observe también que si $\ErrorSt$ es alcanzado en $v_n$ sin la ocurrencia de ninguna falla, la parte nominal de la implementación no se corresponde con la especificación nominal, en cuyo caso $\frac{\pr{1}{r_n}}{1+ \sum^{n}_{i=0} \pr{0}{r_i}}=1$.
Entonces, 
el Refutador quiere maximizar el valor de cualquier corrida, es decir, tratará de de ejecutar fallas que lleven al estado $\ErrorSt$. 
Por el contrario, el Verificador quiere evitar $\ErrorSt$ y entonces tratará de enmascarar fallas de tal forma que se aleje del estado de error. 

Mas precisamente, el valor del juego de masking cuantitativo fuerte para el Refutador se define como $\val_\Refuter(\QMStrGame) = \Sup_{\pi_\Refuter \in \Pi_\Refuter} \; \Inf_{\pi_\Verifier \in \Pi_\Verifier} \FMask(\out(\pi_\Refuter, \pi_\Verifier))$. Análogamente, el valor del juego para el Verificador se define como $\val_\Verifier(\QMStrGame) = \Inf_{\pi_\Verifier \in \Pi_\Verifier} \; \Sup_{\pi_\Refuter \in \Pi_\Refuter} \FMask(\out(\pi_\Refuter, 
\pi_\Verifier))$. Entonces, definimos el valor del juego de masking cuantitativo fuerte, denotado por $\val(\QMStrGame)$, como el valor del juego del Refutador o del Verificador, i.e., $\val(\QMStrGame) = \val_\Refuter(\QMStrGame) = \val_\Verifier(\QMStrGame)$. Esto es posible debido a que los juegos de masking cuantitativos fuertes están determinados como lo probaremos mas abajo en el Teorema~\ref{thm:mask_game_det}. \\

\begin{defi} \label{def:mask_dist}
 Sean $A$ y $A'$ unos sistemas de transición. 
La \emph{distancia de masking fuerte} entre $A$ y $A'$, denotada por $\DeltaMask(A, A')$ se define de la siguiente manera:
$\DeltaMask(A, A') = \val(\QMStrGame).$
\end{defi}

	Nos gustaría remarcar que la \emph{distancia de masking débil} $\DeltaMask^W$ se de fine de la misma forma para el grafo de juego de masking cuantitativo débil $\QMWeakGame$.  A grandes rasgos, estamos interesados en medir la cantidad de fallas que pueden ser enmascaradas. El valor del juego está esencialmente determinado por las transiciones de falla en el grafo de juego y como los jugadores pueden encontrar una estrategia que lleve a (o evite) el estado $\ErrorSt$, independientemente de la existencia de acciones silenciosas.

A continuación, estableceremos algunas propiedades básicas de este tipo de juegos. 
Como ya anticipamos, los juegos de masking cuantitativos fuertes están determinados.

\begin{thm} \label{thm:mask_game_det}
  Para cualquier grafo de juego de masking cuantitativo fuerte $\QMStrGame$ con función de payoff $\FMask$:
%  \vspace{-0.3cm}
  \[\textstyle
  \Inf_{\pi_\Verifier \in \Pi_\Verifier} \; \Sup_{\pi_\Refuter \in \Pi_\Refuter} \FMask(\out(\pi_\Refuter, \pi_\Verifier)) = \Sup_{\pi_\Refuter \in \Pi_\Refuter} \;  \Inf_{\pi_\Verifier \in \Pi_\Verifier} \FMask(\out(\pi_\Refuter, \pi_\Verifier))\]
\end{thm}
\begin{proof} Para demostrar que la función de payoff de masking $\FMask$ está determinada tenemos que probar que es acotada y Borel-medible (teorema de Martin \cite{Martin98}). Primero, $\FMask$ está acotada por definición. Segundo, para ver que $\FMask$ es Borel-medible note que $\FMask(\Omega) \subseteq [0,1]$, y entonces es suficiente para probar que, para cada racional $x$, $\FMask^{-1}((-\infty, x])$ es Borel en la topología de Cantor de ejecuciones infinitas. 
Considere $\FMask^{-1}([-\infty,x])$ para un $x$ arbitrario, esto es lo mismo que $\FMask^{-1}([0, \frac{1}{a}])$ para un $a$ dado. Pero, $\FMask^{-1}([0, \frac{1}{a}]) = \bigcup_{b \geq a} A_b$ donde
$A_b = \bigcup_{i >0} A^i_b$ para $A^i_b = \{ \rho_0 \rho_1 \dots \mid \rho_i = \ErrorSt \wedge \sum^{i-1}_{j=0} \chi_{\Faults}(\pr{1}{\rho_j}) =b\}$. Note que 
$A^i_b = \{ C_{\rho_0 \dots \rho_i} \mid \sum^{i-1}_{j=0} \chi_{\Faults}(\pr{1}{\rho_j}) =b\}$ donde $C_{\rho_0 \dots \rho_i}$ es el cono correspondiente al segmento inicial 
$\rho_0 \dots \rho_i$ el cual es Borel-medible, y por lo tanto $A^i_b$, $A_b$ y $\FMask^{-1}((-\infty, x])$ son Borel-medibles.
\qedhere
%is the set of all sequences $x_0 x_1 x_2 \dots$
%such that we have $b$ or more ones, and this is the union $\bigcup A_i$ being $A_i = \{\sigma \mid \mbox{ number of ones of } \sigma[0,i] = b\}$, which are Borel sets, thus $A$ is a Borel set.
\end{proof} \\


\subsection{Cómputo de la Distancia de Masking}

En esta subsección presentamos los algoritmos para computar la distancia de masking para un juego de masking cuantitativo fuerte (resp. débil). Mostramos que, en el caso de sistemas deterministas, computar la distancia de masking puede ser logrado utilizando un algoritmo de camino mas corto. A diferencia de los sistemas no deterministas, en cuyo caso el computo puede ser realizado por un algoritmo de punto fijo.

Comenzamos presentando el próximo teorema que establece como se calcula el valor de un juego de masking cuantitativo fuerte dado.
%
\begin{thm} \label{thm:quant_game}
  Sea $\QMStrGame$ un grafo de juego de masking cuantitativo fuerte.
  \sloppy Entonces, $\val(\QMStrGame) = \frac{1}{\pr{0}{\delta(\InitVertex^G)}}$, con
  $\delta(\InitVertex^G) = \min \{ (i,j) \mid  \InitVertex^G \in \setsUs \}$, siempre que
  $\InitVertex^G \in U$, y $\val(\QMStrGame)=0$ de otro modo, donde los conjuntos
   $\setsUs$ y $U$ están definidos en Def.~\ref{def:U}.

\end{thm}
\begin{proof} La prueba es por casos:
	
	Si $\InitVertex^G \notin U$, entonces definimos la siguiente estrategia para el Verificador. Si $v \in V_\Verifier \setminus U$, entonces $\pi^*_\Verifier(v)=v'$ 
	para algún $v' \in V_\Refuter \setminus U$, y si $v \notin  V_\Verifier \setminus U$, entonces $\pi^*_\Verifier(v) = v'$ para un $v'$ arbitrario. 
	Probamos por inducción que para cualquier jugada que se conforme a $\pi^*_\Verifier$: $\rho =\rho_0 \rho_1 \dots$ tenemos $\forall i \geq 0: \rho_i \notin V \setminus U$. El caso base es directo. 
Para el caso inductivo, asumamos que $\rho_i \notin V \setminus U$. En caso que $\rho_i \in V_\Verifier$, la propiedad se deduce por definición de
$\pi^*_\Verifier$. Si $\rho_i \in V_\Refuter$, como $\rho_i \in V^G \setminus U$, entonces $\post(\rho_i) \subseteq V^G \setminus U$ (por Def.~\ref{def:U}). 
Por lo tanto, $\rho_{i+1} \in V^G \setminus U$. 
	 Además, también tenemos $\rho_i \neq \ErrorSt$ ya que $\{ \ErrorSt \} \subseteq U$. También note que cualquier jugada que evite el estado $\ErrorSt$ tiene valor $0$: por definición de $\QMStrGame$, cada transición ejecutada por el Refutador debe ser sucedida por una transición seleccionada por el Verificador. Estas transiciones (las elegidas por el Verificador) tienen costo $(1,0)$ ya que el destino de cualquiera de estas transiciones es diferente de $\ErrorSt$. Como tenemos una cantidad infinita de estos movimientos del Verificador, cuando el estado $\ErrorSt$ no es alcanzado, la valuación de estas jugadas es $\lim_{n\rightarrow \infty} \frac{0}{1+ \sum^n_{i=0} \pr{0}{r_i}} = 0$ (recordemos que $r_i = \reward^G(\rho_i)$). 
En resumen, $\sup_{\pi_\Refuter \in \Pi_\Refuter} \FMask(\out(\pi_\Refuter, \pi^*_\Verifier)) = 0$, y como $\FMask$ es positiva
tenemos $\val(\QMStrGame) = \inf_{\pi_\Verifier \in \Pi_\Verifier} \sup_{\pi_\Refuter \in \Pi_\Refuter} \FMask(\out(\pi_\Refuter, \pi_\Verifier)) = 0$.

	Si $\InitVertex^G \in U$, tenemos que $\delta(\InitVertex^G) < (\infty, \infty)$, entonces definimos la siguiente estrategia para el Refutador. 
	Si $v \in U$, entonces $\pi^*_\Refuter(v)= v'$, donde $\delta(v') < \delta(v)$, sino $\pi^*_\Refuter(v)=v'$, para un $v'$ arbitrario. 
	La estrategia $\pi^*_R$ esta bien definida ya que si $v \in \setsUs$, entonces existe un $v' \in \post(v)$ tal que $v \in U^{j-1}_i$ (por Def.~\ref{def:U}). Además, $\delta(v') = (\pr{0}{\delta(v)}, \pr{1}{\delta(v)} - 1)$.  
	Ahora bien, probaremos que para cada estrategia $\pi_\Verifier \in \Pi_\Verifier$ tal que $\out(\pi^*_\Refuter, \pi_\Verifier) = \rho = \rho_0 \rho_1 \dots$ y $\rho_0 \in U$, tenemos:
\begin{equation}\label{eq:inf-bound}
	\FMask(\out(\pi^*_\Refuter, \pi_\Verifier)) \geq \frac{1}{ \pr{0}{\delta(\rho_0)}}
\end{equation} 
		Para demostrar esto, note que, si $\delta(\rho_0)= (i,j)$, entonces $\rho_j =\ErrorSt$ 
		ya que $\pr{1}{\delta(\rho_k)} = \pr{1}{\delta(\rho_{k+1})}+1$ para todo $k$. 
Esto significa que, en $j$ pasos tenemos $\delta(\rho_{j}) = (1,1)$ y entonces $\rho_{j} = \ErrorSt$.
	Esto implica que $\FMask(\rho) =  \lim_{n \rightarrow \infty}  \frac{\pr{1}{r_n}}{1+ \sum^{n}_{i=0} \pr{0}{r_i}} >0$, y también
$ \sum^{\pr{1}{\delta(\rho_0)} + k}_{i=0} \pr{0}{r_i} =  \sum^{\pr{1}{\delta(\rho_0)}}_{i=0} \pr{0}{r_i}$.
	 Es decir, probando que:
\begin{equation}\label{eq:bottom-sum}
 1+ \sum^{\pr{1}{\delta(\rho_0)}}_{i=0} \pr{0}{r_i} \geq \pr{0}{\delta(\rho_0)}
\end{equation} 
tenemos $\FMask(\rho) \geq \frac{1}{ \pr{0}{\delta(\rho_0)}}$. La prueba es por inducción sobre $\delta(\rho_0)$, el caso base es directo.
 Para el caso inductivo, si $\rho_0 \in V_\Refuter$, entonces
\begin{align*}
 	1 + \sum^{\pr{1}{\delta(\rho_0)}}_{i=0} \pr{0}{r_i} & =  1 + \pr{0}{r_0} + \sum^{\pr{1}{\delta(\rho_0)}}_{i=1} \pr{0}{r_i} & \\
					   %  & =   1+\sum^{\pr{1}{\delta(\rho_0)}}_{i=1} \pr{0}{r_i} & \\
					    % & =   1+\sum^{\pr{1}{\delta(\rho_1)}+1}_{i=1} \pr{0}{r_i} & \\
					     & =   1+ \sum^{\pr{1}{\delta(\rho_1)}}_{i=0} \pr{0}{r_{i+1}} &  \text{($\rho_0 \in V_\Refuter$)}\\
					     & \geq \pr{0}{\delta(\rho_1)} & \text{(I.H.)} \\
					     & = \pr{0}{\delta(\rho_0)} & \text{($\rho_0 \in V_\Refuter$)}
\end{align*}
 Si $\rho_0 \in V_\Verifier$ y $\pr{1}{\rho_0} \notin \Faults$, entonces la prueba es como arriba. Si $\pr{1}{\rho_0} \in \Faults$, entonces:
\begin{align*}
 	1+\sum^{\pr{1}{\delta(\rho_0)}}_{i=0} \pr{0}{r_i} & =  1+\pr{0}{r_0} + \sum^{\pr{1}{\delta(\rho_0)}}_{i=1} \pr{0}{r_i} & \\
					 %    & =   2 + \sum^{\pr{1}{\delta(\rho_0)}}_{i=1} \pr{0}{r_i} & \text{($\pr{1}{\rho_0} \in \Faults$)}\\
					  %   & =  2 +  \sum^{\pr{1}{\delta(\rho_1)}+1}_{i=1} \pr{0}{r_i} & \\
					     & =  2 +  \sum^{\pr{1}{\delta(\rho_1)}}_{i=0} \pr{0}{r_{i+1}} &   \text{($\pr{1}{\rho_0} \in \Faults$)}\\
					     & \geq 1 + \pr{0}{\delta(\rho_1)} & \text{(I.H.)} \\
					     & = \pr{0}{\delta(\rho_0)} & \text{($\pr{1}{\rho_0} \in \Faults$)}
\end{align*}
Por lo tanto, la inecuación \ref{eq:bottom-sum} vale. Ahora bien, consideremos la estrategia $\pi^*_\Verifier$ para el Verificador que se define a continuación. Para $v \in U$, $\pi^*_\Verifier(v) = v'$ tal que $\delta(v') = \max \{\delta(v'') \mid v'' \in \post(v)\}$, sino $\pi^*_\Verifier(v) = v'$ para un $v'$ arbitrario. 
Vamos a probar que $\FMask(\out(\pi^*_\Refuter, \pi^*_\Verifier)) = \frac{1}{\pr{0}{\delta(\rho_0)}}$. 
%Let $(\out(\pi^*_\Verifier, \pi^*_\Refuter)) = \rho_0 \rho_1 \dots$.
Note que, por definición de $\pi^*_\Verifier$ y $\pi^*_\Refuter$, tenemos que $\pr{1}{\delta(\rho_{i+1})} = \pr{1}{\delta(\rho_i)} - 1$, %$\pr{1}{\delta(\rho_i)} = \pr{1}{\delta(\rho_{i+1})}+1$
es decir, en a lo sumo $\pr{1}{\delta(\rho_0)}$ pasos alcanzamos $\ErrorSt$. De esta forma, $\lim_{n \rightarrow \infty}  \pr{1}{r_n} =1$. 
Además, si $\pr{1}{\rho_i} \in \Faults$, entonces $\pr{0}{\delta(\rho_{i+1})} = \pr{0}{\delta(\rho_i)} - 1$
por definición de $\pi^*_V$. De este modo, ocurrirán a lo sumo $\pr{0}{\rho_0}$ fallas en $\rho$, y entonces
$\FMask(\out(\pi^*_\Refuter, \pi^*_\Verifier)) = \frac{1}{\pr{0}{\delta(\rho_0)}}$. Por lo tanto, esto y la inecuación \ref{eq:inf-bound} nos da: 
$\inf_{\pi_\Verifier \in \Pi_\Verifier} \FMask(\out(\pi^*_\Refuter, \pi_\Verifier)) = \frac{1}{\pr{0}{\delta(v^G_0)}}$. 


Finalmente, probaremos que no existe una estrategia $\pi^+_\Refuter$  tal que $\sup_{\pi_\Verifier} \FMask(\out(\pi^+_\Refuter, \pi_\Verifier)) < \frac{1}{\pr{0}{\delta(v^G_0)}}$. 
De esta forma, $\pi^*_\Refuter$ es la mejor estrategia. 
Vamos a hacer una prueba por contradicción, asumamos que tenemos tal estrategia. Consideremos $\out(\pi^+_\Refuter, \pi^*_\Verifier) = \rho = \rho_0 \rho_1 \dots$, 
y sea $\delta(\rho_0) = (i,j)$. Entonces, note que, si $\rho_i \in V_\Refuter$, entonces $\pr{0}{\delta(\rho_i)} = \pr{0}{\delta(\rho_{i+1})}$, 
además, si $\rho_i \in V_\Verifier$ entonces $\pr{0}{\delta(\rho_i)} = 1 + \pr{0}{\delta(\rho_{i+1})}$. 
Por lo tanto, $\lim_{n \rightarrow \infty}\sum^n_{0} \pr{0}{r_i} = \frac{1}{\pr{0}{\delta(\rho_0)}}$, lo cual lleva a una contradicción.
Entonces, $\val(\QMStrGame) = \inf_{\pi_\Verifier \in \Pi_\Verifier} \sup_{\pi_\Refuter \in \Pi_\Refuter} \FMask(\out(\pi_\Refuter, \pi_\Verifier)) = \frac{1}{\pr{0}{\delta(v^G_0)}}$.
\qedhere
.

\end{proof} \\

	Interesantemente, el valor del juego para juegos deterministas está dado por el camino más corto (si existe) hacia el estado de error, como se muestra en el siguiente teorema.
\begin{thm}\label{theorem:det-games} Sea  $\QMStrGame = \langle V^G, V_\Refuter,V_\Verifier, E^G, \InitVertex^G, \reward^G \rangle$ un grafo de juego de masking cuantitativo fuerte determinista,
y sea  $G_{\QMStrGame} = \langle V^G,  E^G, \InitVertex^G, w \rangle$ su grafo con pesos subyacente, con la función de peso $w$ 
definida como:
\[
w(v, v') =
\begin{cases} 1 & \text{si $\pr{1}{v'} \in \Faults$} \\
		      0 & \text{en caso contrario}	 
\end{cases}
\]
	Si $\rho = \rho_0 \rho_1  \dots \ErrorSt$ es el camino mas corto (con respecto a la función $w$)
hacia el estado de error en $G_{\QMStrGame}$, y $k$ es la cantidad de fallas que ocurren en $\rho$, entonces: 
\[
	\val(\QMStrGame) = \frac{1}{1+k}
\]
\end{thm}
\begin{proof}
	Definamos la estrategia $\pi_\Refuter \in \Pi_\Refuter$ para el Refutador tal que:
\[
	\inf_{\pi_\Verifier \in \Pi_\Verifier} f_m(\out(\pi_\Refuter, \pi_\Verifier)) = \sup_{\pi_\Refuter' \in \Pi_\Refuter} \inf_{\pi_\Verifier \in \Pi_\Verifier} f_m( \out(\pi_\Refuter',\pi_\Verifier))
\]	
	donde esta estrategia se conforma con el camino mas corto en el grafo subyacente. Asumamos que: 
$\rho_0 \rho_1 \dots \ErrorSt$ es el camino mas corto. Podemos asumir de forma segura que ningún vértice aparece mas de una vez en $\rho$, de lo contrario podemos reducir el camino mas corto eliminando ciclos.
	Teniendo en cuenta esto, definimos la estrategia $\pi_\Refuter$ de la siguiente forma:
\[
	\pi_\Refuter(v) = \begin{cases}
								\rho_{j+1} & \text{si $v = \rho_j$ para algún $j \geq 0$,} \\
								v' & \text{para un $v' \in V_\Verifier$ arbitrario.}
						   \end{cases}
\] 
Primero, vamos a probar que $\inf_{\pi_\Verifier \in \Pi_\Verifier} f_m (\out(\pi_\Refuter, \pi_\Verifier)) = \frac{1}{1+k}$. Sea $\pi_\Verifier$ una estrategia arbitraria para el Verificador. Probemos que la jugada $\rho'_0 \rho'_1 \dots$ que se conforma a $\pi_\Refuter$ y $\pi_\Verifier$ es igual a $\rho$. Esto lo demostramos por inducción sobre $\rho_i$, vale para $\rho_0 = \InitVertex = \rho'_0$. Asumamos que vale para $i=n$, es decir, $\rho'_n = \rho_n$, si $\rho_n = (t, \sigma^1, s', \Verifier)$ (resp.  $\rho_n = (s, \sigma^2, t', \Verifier)$), como $A$ y $A'$ son deterministas, existe un único arco $((t, \sigma^1, s', \Verifier), (t, \#, t', \Verifier)) \in E^G$ (resp. $((s, \sigma^1, t', \Verifier), (t, \#, t', \Verifier)) \in E^G$) y por lo tanto  $\rho'_{n+1} = \pi_\Verifier( \rho'_n) = (t, \#, t', \Verifier) = \rho_{n+1}$. Si 
$\rho'_n = \rho_n = (s, \#, s', \Refuter)$ entonces $\rho'_{n+1} = \pi_\Refuter(\rho'_n) = \pi_\Refuter(\rho_n) = \rho_{n+1}$. 
	
	Adicionalmente, la valuación de $\rho$ es $\frac{1}{1+k}$, es decir, obtenemos:
\begin{equation} \label{eq1}
\begin{split}
 f_m (\out(\pi_\Refuter, \pi_\Verifier))  =  \frac{1}{1+k},
\end{split}
\end{equation}	
y como esto vale para cualquier $\pi_\Verifier$, obtenemos:
\begin{equation} \label{eq1}
\begin{split}
\inf_{\pi_V \in \Pi_V} f_m (\out(\pi_\Refuter, \pi_\Verifier))  =  \frac{1}{1+k}
\end{split}
\end{equation}

Ahora bien, asumamos que hay una estrategia $\pi_\Refuter'$ para el Refutador tal que 
$\inf_{\pi_V \in \Pi_V} f_m (\out(\pi_\Refuter', \pi_\Verifier)) > \inf_{\pi_\Verifier \in \Pi_\Verifier} f_m (\out(\pi_\Refuter, \pi_\Verifier))$.
De (\ref{eq1}) tenemos que $\inf_{\pi_\Verifier \in \Pi_\Verifier} f_m(\out(\pi_\Refuter', \pi_\Verifier)) > \frac{1}{1+k}$. 
De esta forma, la cantidad de fallas observadas en 
$\inf_{\pi_\Verifier \in \Pi_\Verifier} f_m(\out(\pi_\Refuter', \pi_\Verifier))$ debería ser menor a $k$. 
Pero, seria un camino mas corto en el grafo subyacente, lo cual es una contradicción. Por lo tanto, tenemos que:
\[	
	\inf_{\pi_\Verifier \in \Pi_\Verifier} f_m(\out(\pi_\Refuter, \pi_\Verifier)) = \sup_{\pi_\Refuter' \in \Pi_\Refuter} \inf_{\pi_\Verifier \in \Pi_\Verifier} f_m( \out(\pi_\Refuter',\pi_\Verifier)).
\]	
\qedhere
\end{proof} \\

	Notemos que los teoremas~\ref{thm:mask_game_det}, \ref{thm:quant_game} y \ref{theorem:det-games} aplican también a 
$\QMWeakGame$.
	El teorema~\ref{theorem:det-games} nos permite proveer procedimientos eficientes para decidir juegos cuantitativos en el caso de sistemas deterministas. Para el caso de sistemas no deterministas, el procedimiento es mas costoso computacionalmente (en términos de tiempo y memoria) que para el caso de sistemas deterministas, ya que los conjuntos $\setsUs$ (Def.~\ref{def:U}) deben ser computados. \\

Es importante destacar que, para sistemas no deterministas, el camino mas corto no siempre determina estrategias ganadoras. Esto se puede observar a través de un ejemplo simple a continuación. Consideremos los dos sistemas de transición que se muestran en la figura ~\ref{fig:two-nondet-systems}.

\begin{figure} [h]
\begin{center}
    \includegraphics[scale=0.5]{images/nondeterm.eps} 
    \caption{Dos sistemas no deterministas}
    \label{figure:nondeterm}\label{fig:two-nondet-systems}
\end{center}
\end{figure}
\begin{figure} [h]
\begin{center}
    \includegraphics[scale=0.5]{images/nondeterm-game.eps} 
    \caption{El juego cuantitativo para los sistemas $M$ y $M'$}
    \label{figure:nondeterm-game}
\end{center}
\end{figure}

En este ejemplo, el no-determinismo está dado por la acción $b$. Note también que hay una falla en $M'$ que conecta los estados $t_2$ y $t_3$. El juego cuantitativo para estos sistemas se muestra en la figura~\ref{figure:nondeterm-game}. Notemos que cualquier camino mas corto en este grafo con respecto a la función de peso $w$ tiene valor $1$ (cualquier camino en el grafo que evite las fallas). Sin embargo, el valor del juego es $\frac{1}{2}$ ya que la mejor estrategia del Refutador es llevar al Verificador al estado $(s_2,b^1,t_1,\Verifier)$. 
Desde ahí, como el Verificador quiere minimizar el valor del juego, su mejor jugada es hacer un movimiento hacia el estado $(s_2,\#,t_2,\Refuter)$. Entonces, el Refutador puede elegir una falla que lleva al estado de error. \\
%Note that the value of this game is $\frac{1}{2}$.\\

La observación anterior sugiere que se necesita un algoritmo diferente para computar la distancia de masking para sistemas no deterministas. 
La idea principal es computar los conjuntos $\setsUs$ que fueron definidos en Def.~\ref{def:U} a través de un algoritmo de punto fijo. Para ser mas precisos, los conjuntos $\setsUs$ pueden ser calculados utilizando una búsqueda a lo ancho de abajo hacia arriba ( 
bottom-up breadth-first) desde el estado de error. 
El algoritmo \ref{Alg:MainAlg} muestra el pseudo-código para resolver cualquier juego cuantitativo de masking fuerte (resp. débil). 
El algoritmo toma como entrada un grafo de juego cuantitativo de masking fuerte  $\QMStrGame = \langle V^G, V_\Refuter, V_\Verifier,E^G, \InitVertex^G, \reward^G \rangle$ 
y computa el valor del juego, i.e., $\val(\QMStrGame)$.
%Let us describe the essential steps of the algorithm for solving any quantitative strong (resp. weak) masking game. 
El algoritmo etiqueta los nodos del grafo con los índices $i$ y $j$. 
%The algorithm can be understood as follows. 
Los pasos principales del algoritmo se detallan a continuación:


\begin{enumerate}
  \item Cada vértice $v$ esta etiquetado con un par $(i, j)$ que representa que $v \in U_{i}^{j}$. Inicialmente, $\ErrorSt$ está etiquetado con $(1, 1)$ y todos los demás nodos están etiquetados con $(\infty, \infty)$ (lineas \ref{Alg:InitB}-\ref{Alg:InitE}). 
  Además, usamos la asignación $\Q \gets \emptyset$ para denotar la creación de una cola vacía. 
  Después, encolamos el estado de error (lineas \ref{Alg:CreateQ}-\ref{Alg:LoopB}). También mantenemos un conjunto $\STB$ que contiene los estados estabilizados, i.e. estados cuyas etiquetas son finales. Los estados que no son alcanzables desde el estado de error son ignorados.
  \item Desde el estado de error se lleva a cabo una búsqueda a lo ancho de abajo hacia arriba (bottom-up breadth-first) utilizando una cola de prioridad $\Q$ (lineas \ref{Alg:LoopB}-\ref{Alg:LoopE}), donde el estado con la etiqueta mas pequeña (en orden lexicográfico) tiene mayor prioridad. 
  Sea $v'$ el vértice con la prioridad mas alta en la cola. Entonces, para todo predecesor $v$ de $v'$ se ejecutan los siguientes pasos (lineas \ref{Alg:LoopBPre}-\ref{Alg:LoopEPre}):
  \begin{itemize}
    \item Si $v$ es un nodo del Verificador (resp. un nodo del Refutador), entonces obtenemos la máxima (resp. mínima) etiqueta $(i,j)$ de todos sus sucesores con respecto al orden lexicográfico. Adicionalmente, si $v$ es un vértice del Verificador y todos sus sucesores están en $\STB$, entonces $v$ se añade al conjunto. En el caso que $v$ sea un vértice del Refutador, 
    el vértice simplemente se añade sin restricción alguna. 
    \item Actualizar el valor de $(i,j)$ incrementando $j$ e incrementando $i$ solo si $\pr{1}{v} \in \Faults$. Llamemos $(i',j')$ a esta nueva etiqueta.
    \item Si $i'$ es diferente del primer componente de la etiqueta actual de $v$, entonces se actualiza y se agrega $v$ a la cola. 
    Observemos que el mismo nodo puede ser añadido a la cola mas de una vez a medida que las etiquetas de sus sucesores cambian.
  \end{itemize}
  \item Cuando la cola está vacia, 
  el algoritmo termina y retorna el valor del juego (lineas \ref{Alg:EndB}-\ref{Alg:EndE}). 
  Intuitivamente, el procedimiento para tan pronto como las etiquetas de todos los estados en el grafo de juego alcanzan su valor final (punto fijo). 
  Sea $k$ la primer componente de la etiqueta del estado inicial, entonces el valor del juego es $0$ si 
  $k = \infty$, y $\frac{1}{k}$ en caso contrario.\\
\end{enumerate}
\begin{algorithm}[t]
\SetAlgoLined
\KwIn{Juego de Masking Cuantitativo Fuerte $\QMStrGame = \langle V^G, V_\Refuter, V_\Verifier,E^G, \InitVertex^G, \reward^G \rangle$}
\KwOut{$\val(\QMStrGame)$}
 Etiquetar $\ErrorSt$ con $(1,1)$\; \label{Alg:InitB}
 Etiquetar cada nodo en $V^G \setminus \{\ErrorSt\}$ con $(\infty,\infty)$\; \label{Alg:InitE}
 %$\Q \gets \emptyset$ \tcp*{$\Q$ is a priority queue}  \label{Alg:CreateQ}
 $\Q \gets \emptyset$ \tcp*{$\Q$ es una cola de prioridad}  \label{Alg:CreateQ}
 $\STB \gets \{\ErrorSt\}$\; \label{Alg:CreateSTB}
 %$\mathcal{VE} \longleftarrow \emptyset$\; \label{Alg:CreateVE} 

 $\enqueue(\Q, \ErrorSt)$\; \label{Alg:LoopB} 
 \While{$\Q$ no está vacía}{ \label{Alg:While} 
 	 $s' \gets \dequeue(\Q)$\; \label{Alg:Dequeue-Node}
 	 %\lIf{$\{s'\xrightarrow{\sigma}t \mid t \in post(s')\} \subseteq \mathcal{VE}$}{ \label{Alg:UpdateSTB}
	%	$\mathcal{STB} \longleftarrow \mathcal{STB} \cup \{s'\}$
	 %}
	 
	 \For{$v \in \pre(v') \wedge v \notin \STB$ }{ \label{Alg:LoopBPre}
	 %\For{$s\xrightarrow{\sigma}s' \in E^G$}{ \label{Alg:LoopBPre}
	 	\If{$v \in V_\Verifier$}{
	 		$\lbl \gets \maxlabel(\post(v))$\; \label{Alg:V-Update}
	 		\lIf{$\post(v) \subseteq \STB$}{ \label{Alg:UpdateSTB}
	 		$\STB \gets \STB \cup \{v\}$ 
	 		}
	 		%$enq \longleftarrow post(s) \subseteq \mathcal{STB}$
	 	}
	 	\Else{
	 		$\lbl \gets \minlabel(\post(v))$\; \label{Alg:R-Update}
	 		%$enq \longleftarrow post(s) \cap \mathcal{STB} \neq \emptyset$
	 		$\STB \gets \STB \cup \{v\}$ \label{Alg:R-STB-Update}
	 	}
	 	$\pr{1}{\lbl} \gets \pr{1}{\lbl} + 1$ \tcp*{asumimos $\infty+1=\infty$} \label{Alg:Inc_j}
	 	\lIf{$\pr{1}{v} \in \Faults$}{
	 		$\pr{0}{\lbl} \gets \pr{0}{\lbl} + 1$  \label{Alg:Inc_i}
	 	}
	 	\If{$\pr{0}{\Label(v)} \neq \pr{0}{\lbl}$}{ \label{Alg:Insert-Cond}
	 		Etiquetar $v$ con $\text{lbl}$\;
	 		$\text{Enqueue}(\Q, v)$  \tcp*{$v$ tiene prioridad $\Label(v')$} \label{Alg:Enqueue-Vertex}
	 		%$\mathcal{VE} \longleftarrow \mathcal{VE} \cup \{s\xrightarrow{\sigma}s'\}$
	 	}
	 } \label{Alg:LoopEPre}
 } \label{Alg:LoopE}
 %\lIf{$\pr{0}{Label(s_{0}^G)} \neq \infty$}{ \label{Alg:EndB}
 \lIf{$\InitVertex^G \in \STB$}{ \label{Alg:EndB}
	$\result \gets \frac{1}{\pr{0}{\Label(\InitVertex^G)}}$
 }
 \lElse{
	$\result \gets 0$ \label{Alg:Ret0}
 }
 \Return{$\result$}\; \label{Alg:EndE}
 \caption{Computando el valor del juego de masking cuantitativo fuerte} \label{Alg:MainAlg} 
\end{algorithm}


	 Vamos a demostrar que el algoritmo termina y que es correcto.

\sloppy \begin{thm}\label{th:alg-termination}  \textbf{(Terminación)} El Algoritmo \ref{Alg:MainAlg} termina.
\end{thm}
\begin{proof}
	Probemos que un vértice no puede ser añadido una cantidad no acotada de veces a $\Q$. 
Primero, note que las lineas \ref{Alg:LoopBPre} y \ref{Alg:R-STB-Update} del Algoritmo  \ref{Alg:MainAlg} implican que los vértices del Refutador solo se agregan una vez a la cola. 
Por lo tanto, solo los vértices del Verificador pueden ser añadidos a a $\Q$ una cantidad no acotada de veces.
Probaremos por contradicción que este no es el caso. 
Asumamos que $v$ es un vértice del Verificador que es agregado infinitas veces a la cola. 
Esto implica que $v \notin \STB$ es siempre verdadero dentro del ciclo, y entonces 
$\post(v) \cap (V^G \setminus \STB) \neq \emptyset$ (d lo contrario $v$ seria insertado en $\STB$, linea \ref{Alg:UpdateSTB}). 
Esto significa que,  algún nodo $w \in \post(v)$ del Refutador debe satisfacer $\post(w) \cap \STB = \emptyset$. 
Mas aun, también tenemos $\Label(w) = (\infty, \infty)$ ya que este es el valor inicial que se asigna a $w$, 
y la única manera de modificarlo es ejecutando la linea \ref{Alg:R-Update}, 
en tal caso, $w$ sera agregado a $\Q$, lo cual contradice lo que asumimos. 
Pero la etiqueta de $v$ se calcula siempre tomando el máximo de sus sucesores (linea \ref{Alg:V-Update}), es decir, 
$\Label(v) = (\infty, \infty)$ debe valer dentro del ciclo, y como definimos $\infty + 1 = \infty$, la condición en la linea \ref{Alg:Insert-Cond} siempre es falsa.
Por lo tanto $v$ nunca es agregado a la cola, lo cual contradice nuestro supuesto inicial. 
En resumen, ningún nodo se puede agregar un numero no acotado de veces a la cola. Por esto, 
la cola eventualmente se vacía y el algoritmo termina.
\qedhere
\end{proof} 
\sloppy \begin{thm}\label{th:alg-correctness} \textbf{(Correctitud)} Al terminar, el Algoritmo \ref{Alg:MainAlg} 
retorna el valor del grafo juego cuantitativo de masking fuerte (respec. débil) $\QMStrGame$.
\end{thm}
\begin{proof}
	Consideremos la función  $\delta(v) = \min \{(i,j) \mid v \in \setsUs\}$, donde $\min \emptyset = (\infty, \infty)$.
También consideramos la extensión de esta función a conjuntos, es decir, $\delta(W) = \{\delta(w) \mid w \in W \}$. 
Además, las siguientes propiedades de $\delta$ son una consecuencia de la definición \ref{def:U}: \\

\noindent
Si $v$ es un vértice del Refutador:
\begin{equation}\label{prop:delta-1}
 \delta(v)  = \min \{(i,j+1) \mid (i,j) \in \delta(\post(v)) \}
\end{equation}
Si $v$ es un vértice del Verificador y $\pr{1}{v} \in \Faults$ entonces:
\begin{equation}\label{prop:delta-2}
 \delta(v)  = \max \{(i+1,j+1) \mid (i,j) \in \delta(\post(v)) \}
\end{equation}
Si $v$ es un vértice del Verificador y $\pr{1}{v} \notin \Faults$ entonces:
\begin{equation}\label{prop:delta-3}
 \delta(v) = \max \{(i,j+1) \mid (i,j) \in \delta(\post(v)) \}
\end{equation}
	Ahora bien, probemos que los siguientes predicados siempre valen después de la linea \ref{Alg:While}.
\begin{equation}\label{Alg:inv0}
	\forall v \in \STB : \Label(v) < (\infty, \infty)
\end{equation}
\begin{equation}\label{Alg:inv1}
	\forall w, v \in S^G : v \in \STB \wedge \Label(w) < \Label(v) \Rightarrow w \in \STB
\end{equation}
%and 
\begin{equation}\label{Alg:inv2}
	\forall v \in \STB : \Label(v) = \delta(v)
\end{equation}

	Prueba de la propiedad \ref{Alg:inv0}: vale para la inicialización (linea \ref{Alg:CreateSTB}). Vamos a hacer la prueba por contradicción. 
Sea $v$ el primer nodo agregado a $\STB$ tal que $\Label(v) = (\infty, \infty)$.
Si es un vértice del Refutador, entonces $\post(v) \cap \STB \neq \emptyset$ y como $v$ era el primer nodo agregado a $\STB$ con 
$\Label(v) = (\infty, \infty)$ tenemos que $\forall w \in \post(v) \cap \STB: \Label(w) < (\infty, \infty)$. Pero entonces, en la linea \ref{Alg:R-Update},
$v$ es etiquetado con una etiqueta diferente de $(\infty, \infty)$ lo cual es una contradicción. 
De forma similar, si $v$ es un vértice del Verificador, entonces $\post(v) \subseteq \STB$ y 
por lo tanto se lo etiqueta en la linea \ref{Alg:V-Update} con un valor diferente de $(\infty, \infty)$, lo cual contradice nuestro supuesto inicial. 
Por consiguiente, $\forall v \in \STB : \Label(v) < (\infty, \infty)$.

	Prueba de la propiedad \ref{Alg:inv1}: $\STB$ se inicializa con $\{\ErrorSt \}$ y por lo tanto la propiedad vale antes de la linea \ref{Alg:While}. 
De nuevo hacemos la prueba por contradicción, asumamos que $v$ es el primer nodo agregado a $\STB$ que no cumple con la propiedad, es decir, existe un $w$ tal que $\Label(w) < \Label(v)$ y
$w \notin \STB$; además, asumamos que $w$ es e vértice con la etiqueta mas pequeña que satisface esto. 
Como $v \in \STB$ tenemos $\Label(v)<(\infty, \infty)$ (por Prop.~\ref{Alg:inv0}) y entonces $\Label(w)< (\infty, \infty)$. 
De hecho, $w$ no puede ser un vértice del Refutador, de lo contrario, al ser etiquetado, tendría que ser agregado a $\STB$ (linea \ref{Alg:R-STB-Update}), 
contradiciendo nuestros supuestos. 
Ahora bien, si $w$ es un vértice del Verificado y $\Label(w) < (\infty, \infty)$
ya que $\Label(w) = \max\{\Label(z) \mid z \in \post(w)\}$ (linea \ref{Alg:R-Update}), tenemos: $\forall z \in \post(w) : \Label(z) < (\infty, \infty)$.
Además, por transitividad tenemos que $\forall z \in \post(w) : \Label(z) < \Label(v)$. Pero como asumimos que 
$w$ era el vértice con la menor etiqueta que satisface $\Label(w) < \Label(v)$ y $w \notin \STB$, tenemos que $\forall z \in \post(v) : z \in \STB$. Pero entonces cuando $v$ fue inspeccionado en la linea \ref{Alg:UpdateSTB} este fue agregado a $\STB$, 
lo cual lleva a una contradicción.

	Prueba de la Propiedad \ref{Alg:inv2}: la propiedad vale para $\ErrorSt$. Sea $v$ el primer vértice agregado a $\STB$ tal que $\Label(v) \neq \delta(v)$. En el caso que $v$ es un vértice del Verificador, entonces, 
	como $v \in \STB$, tenemos $\post(v) \subseteq \STB$. Además, asumimos que $v$ era el primer vértice que viola esta propiedad,  
	entonces tenemos que $\forall w \in \post(v):\delta(w)=\Label(w)$. Además, si $\pr{1}{v} \notin \Faults$, entonces: 
\begin{align*}
\Label(v) & = \max \{(i,j+1) \mid (i,j) \in \Label(\post(v))\}&  \text{(Lineas \ref{Alg:V-Update} y \ref{Alg:Inc_j})}\\
	      & =  \max \{(i,j+1) \mid (i,j) \in \delta(\post(v))\}&  \text{(Suposición)}\\
	      & = \delta(v)& \text{(Prop. \ref{prop:delta-3})}
\end{align*}
lo cual es una contradicción. Ahora bien, en el caso que $\pr{1}{v} \in \Faults$ tenemos que:
\begin{align*}
\Label(v) & = \max \{(i+1,j+1) \mid (i,j) \in \Label(\post(v))\}&  \text{(Lineas \ref{Alg:V-Update}, \ref{Alg:Inc_j}, y \ref{Alg:Inc_i})}\\
	      & =  \max \{(i+1,j+1) \mid (i,j) \in \delta(\post(v))\}&  \text{(Suposición)}\\
	      & = \delta(v)& \text{(Prop. \ref{prop:delta-2})}
\end{align*}
lo cual también contradice nuestra suposición. Por lo tanto, $v$ no puede ser un vértice del Verificador. 
En el caso que $v$ sea un vértice del Refutador, como $v \in \STB$ tenemos que $\Label(v) < (\infty, \infty)$ por la Prop.~\ref{Alg:inv0}. 
Por lo tanto, cuando $v$ fue agregado a $\STB$, $\Label(v) = \min\{ \Label(w) \mid w \in \post(v)\}$. Por consiguiente, 
existe un $w \in \post(v)$ tal que $\Label(w) \leq \Label(v)$, pero entonces por la Prop.~\ref{Alg:inv1} 
tenemos $w \in \STB$. De este modo:
\begin{align*}
\Label(v) & = \min \{(i,j+1) \mid (i,j) \in \Label(\post(v))\}&  \text{(Lineas \ref{Alg:R-Update} y \ref{Alg:Inc_j})} \\
	      & =  \min \{(i,j+1) \mid (i,j) \in \delta(\post(v))\}&  \text{(Suposición)}\\
	      & = \delta(v)& \text{(Prop. \ref{prop:delta-2})}
\end{align*}
lo cual contradice nuestras suposiciones. Por esto, $\Label(v) = \delta(v)$.

	Ahora bien, vamos a probar que cuando el ciclo de la linea \ref{Alg:LoopBPre} termina tenemos:
\begin{equation}\label{Alg:inv3}
 \forall v \in S^G \setminus \STB : \delta(v)=(\infty, \infty)
\end{equation}

Vamos a hacer la prueba por contradicción. Sea $v \in S^G \setminus \STB$ tal que $\delta(v) < (\infty, \infty)$ y, además, asumamos que
%$\delta(v) = \min \{w \in S^G \setminus \STB \mid \delta(w) < (\infty, \infty) \}$.
$\delta(v)$ es la etiqueta mas pequeña que satisface esto.
Si $v$ es un vértice del Refutador, entonces existe algún $w \in \post(v)$ tal que $\delta(w) < \delta(v)$. 
Por lo tanto, tenemos que $w \in \STB$ (por nuestra suposición) lo cual significa que $v$ fue agregado al menos una vez a la cola ya que fue inicializado con $(\infty, \infty)$. 
De este modo, fue agregado a $\STB$ en la linea \ref{Alg:R-STB-Update}, lo cual contradice nuestro supuesto inicial. 
Por lo tanto, $v$ debe ser un vértice del Verificador. 
Si $\pr{1}{v} \in \Faults$, entonces $\delta(v) = \max \{(i+1,j+1) \mid (i,j) \in \delta(\post(v))\}$ 
y por lo tanto $\delta(v) > \delta(w)$ para todo $w \in \post(w)$.
Entonces, por nuestras suposiciones, $w \in \STB$ para todo $w \in \post(v)$.
Además, cuando el ultimo $w \in \post(v)$ fue agregado a $\STB$, $v$ estuvo en la cola debido a la política de recorrido primero en lo ancho (BFS).
De hecho, cuando la condición $\post(v) \subseteq \STB$ fue evaluada para $v$ (linea \ref{Alg:UpdateSTB}), es verdadera y entonces $v$ 
debería ser agregado a $\STB$, contradiciendo nuestra suposición. Por lo tanto, $v \in \STB$.

Finalmente, el resultado computado por el Algoritmo \ref{Alg:MainAlg} se deduce de las propiedades \ref{Alg:inv2}, \ref{Alg:inv3}, 
y el Teorema \ref{thm:quant_game}. 
Entrando mas en detalle, si $\delta(s_{0}^G) = (\infty, \infty)$, entonces por Prop. ~\ref{Alg:inv0} y \ref{Alg:inv3}, tenemos que cuando termina, $\Label(s_{0}^G) = (\infty, \infty)$. 
De este modo, el algoritmo retorna $0$ en la linea \ref{Alg:Ret0} lo cual es correcto por el Teorema~\ref{thm:quant_game}. 
En el caso que $\delta(s_0^G)< (\infty, \infty)$, entonces $s_0^G \in \STB$ y también que Prop.~\ref{Alg:inv2} tenemos $\Label(v) = \delta(v)$. Por lo tanto, el algoritmo retorna el resultado correcto en la linea \ref{Alg:EndB} por el Teorema \ref{thm:quant_game}. 
\qedhere
\end{proof}




Nos queda discutir la complejidad del tiempo de ejecución para computar el valor de juegos cuantitativos de masking. 
El siguiente teorema establece cual es la complejidad de determinar el valor de cualquier tipo de juegos cuantitativos de masking.
%
%\noindent
%Finally, winning regions (and strategies) can be computed in lineal time.  
\sloppy \begin{thm}\label{th:qgame-determined} Cualquier grafo de juego cuantitativo de masking fuerte (resp. débil) 
$\QMStrGame = \langle V^G, V_\Refuter, V_\Verifier, E^G, \InitVertex^G, \reward^G \rangle$ puede ser determinado en tiempo $\BigO(|E^G|*\log |V^G|)$ (resp. $\BigO(|E_W^G|*\log |V^G|)$).
\end{thm}
\begin{proof}
	Notemos que el ciclo de la linea \ref{Alg:LoopBPre} inspecciona los arcos del grafo. Además, notemos que, ningún arco $(v, v')$ se puede inspeccionar dos veces:
	si $v'$ es un vértice del Refutador, entonces sera agregado a $\STB$ y el arco no puede ser procesado nuevamente. 
	Si $v$ es un vértice del Verificador, entonces $v'$ es un vértice del Refutador, por lo que una vez desencolado (linea \ref{Alg:Dequeue-Node}), no será agregado a la cola de nuevo, y por lo tanto el arco $(v, v')$ no sera procesado de nuevo. Por esto, el ciclo de la linea \ref{Alg:LoopBPre} será ejecutado $|E^G|$ veces en el peor caso. 
	Además, si se utiliza una implementación eficiente de colas de prioridad para almacenar los estados (linea \ref{Alg:Enqueue-Vertex}), 
	entonces tomaría $\BigO(\log |V^G|)$ pasos la inserción o eliminación de un elemento en la cola, es decir, en total, el ciclo de la linea \ref{Alg:LoopBPre} toma $\BigO(|E^G|*\log |V^G|)$ pasos.
	Adicionalmente, notemos que el \emph{ciclo while} de la linea \ref{Alg:While} se ejecuta hasta que $\Q$ se vacíe, y los nodos solo son encolados en la linea \ref{Alg:Enqueue-Vertex}. Por lo tanto, la cantidad de veces que el \emph{ciclo while} es ejecutado está acotado por el numero de veces que el \emph{ciclo for} 	es ejecutado, lo cual implica que el ciclo exterior es ejecutado a lo sumo $O(|E^G|)$ veces. Estas consideraciones son similares para el caso de los juegos cuantitativos de masking débil.	

\qedhere
\end{proof} \\
% TBD similar for weak games

Los teoremas \ref{th:game-determined} y \ref{th:qgame-determined} describen la complejidad de resolver los juegos de masking estándar y cuantitativos respectivamente. Sin embargo, en la practica, uno necesita tener en cuenta que $|V^G| = |S|*|S'|$ y $|E^G| = |{\rightarrow}|+|{\rightarrow'}|$, así que construir el juego toma 
$\BigO(|S|^2*|S'|^2)$ pasos en el peor caso. Adicionalmente, para juegos débiles, la clausura transitiva del modelo original necesita ser computada, lo cual cuesta $\BigO(\max(|S|,|S'|)^{2.3727})$ para el mejor algoritmo conocido \cite{Wil12}.

	Es interesante destacar que los juegos deterministas pueden ser resueltos en tiempo lineal utilizando el hecho demostrado en el Teorema \ref{theorem:det-games}.
\begin{thm}\label{th:deterministic-qgame-complexity} 
  Cualquier juego de masking determinista fuerte (resp. débil) puede ser resuelto en tiempo $\BigO(|E^G|)$ (resp. $\BigO(|E_W^G|)$).
\end{thm}
\begin{proof} Por el Teorema \ref{theorem:det-games}, el valor del juego está dado por el camino mas corto hacia el estado de error en el grafo de juego donde la función de peso asigna $1$ a las fallas, y $0$ a otras transiciones. El algoritmo de Dial \cite{Dial69} puede ser utilizado para obtener el camino mas corto en este grafo, el cual tiene complejidad $\BigO(|E^G|)$  (resp. $\BigO(|E^G_W|)$ en el caso de los juegos débiles).
\qedhere
\end{proof} 

Observemos que al utilizar los conjuntos $\setsUs$ podemos definir estrategias óptimas para el Refutador y el Verificador, sin tener en cuenta la historia de la jugada. Esto significa que podemos dar el siguiente teorema.
 
\begin{thm} \label{thm:memoryless} Sea $\QMStrGame$ un grafo de juego cuantitativo de masking fuerte.
  Los jugadores $\Refuter$ y $\Verifier$ tienen estrategias óptimas sin memoria para $\QMStrGame$.
\end{thm}
\begin{proof} Para un juego dado podemos computar los conjuntos $\setsUs$ utilizando el Algoritmo~\ref{Alg:MainAlg}.
Por esto, se puede definir de forma directa una estrategia óptima para el Refutador. 
Para un nodo dado $v$, si este pertenece a algún $\setsUs$, entonces el Refutador elige algún nodo en $U^{j'}_{i'}$ donde: 
$(i', j') = \text{max}\{(i'', j'') \mid post(v) \cap U^{j}_{i} \neq \emptyset \wedge (i'',j'') < (i,j) \}$. 
Por definición de $\setsUs$, sabemos que el susodicho par existe, y también que esta estrategia es ganadora para el Refutador. Si $v \notin \setsUs$, entonces cualquier elección del Refutador llevará a una jugada ganadora del Verificador. 
Por lo tanto, el Refutador se mueve a cualquier sucesor de $v$.
De forma similar, podemos definir una estrategia óptima para el Verificador.
\qedhere 
\end{proof} \\

%% \noindent
%% Now, we present some basic properties of the masking distance.

Al utilizar $\QMWeakGame$ en lugar de $\QMStrGame$ en la 
Def.~\ref{def:mask_dist}, podemos definir la \emph{distancia de masking débil} $\DeltaMask^W$. El próximo teorema establece que $A$ y
$A'$ están a distancia $0$ si y solo si existe una simulación de masking fuerte (o débil) entre ellos.

\begin{thm}\label{theorem:ref}
  Para cualquier par de sistemas de transición $A = \langle S, \Sigma, \rightarrow, \InitState \rangle$ y $A' = \langle S', \Sigma_{\mathcal{F'}}, \rightarrow', \InitStatePrime \rangle$, vale que:
  \begin{enumerate}[(i)]
  \item  $\DeltaMask(A,A') = 0$ si y solo si $A \Masking A'$, y
   \item $\DeltaMask^W(A,A') = 0$ si y solo si $A \WeakMasking A' $.
  \end{enumerate}
\end{thm}
%
Esto se deduce del Teorema \ref{thm:quant_game}.
%That is, the masking distance between two systems is $0$ if and only if there is a masking simulation between them.
Si notamos que $A \Masking A$ (y $A \WeakMasking A$) para cualquier sistema de transición $A$, obtenemos que $\DeltaMask(A,A)=0$ (resp.\ $\DeltaMask^W(A,A)=0$) por el Teorema \ref{theorem:ref}, i.e., 
las dos distancias son reflexivas.

Para nuestro ejemplo de la celda de memoria, la distancia de masking es de $1/3$ 
con una redundancia de $3$ bits y considerando dos fallas. 
Esto significa que solo una falla pudo ser enmascarada de forma exitosa por esta implementación. \\

Podemos probar una versión de la desigualdad triangular para nuestra noción de distancia.
%
\begin{thm} \label{thm:triang_ineq}
  Sean $A = \langle S, \Sigma, \rightarrow, s_0 \rangle$, $A' = \langle S', \Sigma_{\mathcal{F'}}, \rightarrow', s'_0 \rangle$,  y  $A'' = \langle S'', \Sigma_{\mathcal{F''}},\rightarrow'', s''_0 \rangle$ unos sistemas de transición tales que $\Faults' \subseteq \Faults''$, y los juegos correspondientes $\mathcal{Q}_{A,A'}$, $\mathcal{Q}_{A',A''}$ y $\mathcal{Q}_{A,A''}$.
  Entonces $\DeltaMask(A,A'') \leq \DeltaMask(A,A') + \DeltaMask(A', A'')$ y
  $\DeltaMask^W(A,A'') \leq \DeltaMask^W(A,A') + \DeltaMask^W(A', A'').$
\end{thm}
\begin{proof} 
Probaremos que para cualquier nodo $(s,\#,s'',\Refuter)$ en $\mathcal{Q}_{A,A''}$ y para cualquier par de nodos
$(s,\#, s', R)$ en $\QMStrGame$ y $(s',\#,s'', R)$ en $\mathcal{Q}_{{A'},A''}$ (para cualquier estado $s'$ en $A'$), se cumple que:
\[
\frac{1}{\pr{0}{\delta((s,\#, s'', \Refuter))}} \leq \frac{1}{\pr{0}{(\delta(s,\#, s', R))}} + \frac{1}{\pr{0}{\delta((s',\#, s'', R))}}
\] 
donde $\delta(v) = \min \{(i,j) \mid v \in U^i_j\}$, calculado en el juego correspondiente. 
Como en el Teorema \ref{thm:quant_game}, solo definimos $\max \emptyset = (\infty, \infty)$. 
El resultado se deduce de este hecho y el Teorema \ref{thm:quant_game}. La prueba es por inducción sobre $\delta((s,\#, s'', \Refuter))$.

Primero, observemos que para cualquier nodo $(s, \#, s'', \Refuter)$ del juego $\mathcal{Q}_{A,A''}$ debemos tener $\delta((s, \#, s'', \Refuter)) \geq (1,3)$.
De hecho, este nodo no puede ser el estado de error, lo cual significa que $j \neq 1$. Además, luego del movimiento del Refutador tenemos al menos un movimiento del Verificador y por lo tanto $j \geq 3$. Es decir que el caso base es $\delta((s,\#, s'', \Refuter)) = (1,3)$.
\begin{description}
\item [Caso Base] Si $\delta((s,\#, s'', \Refuter)) = (1,3)$. Asumamos que $(s, \#, s'', R) \in U^3_1$. Esto significa que tenemos una transición 
$((s, \#, s'', \Refuter), (w, \sigma^t, w'', \Verifier))$, donde $t \in \{1,2\}$, que no puede ser emparejada por el Verificador. 
En el caso que $t=1$, entonces este movimiento es una transición $((s, \#, s'', \Refuter), (w, \sigma^1, s'', \Verifier))$ de $A$. 
Ahora bien, sean $(s, \#, s', \Refuter)$ y $(s', \#, s'', \Refuter)$ un par de estados de $\QMStrGame$ y $\mathcal{Q}_{A',A''}$, respectivamente. 
Por definición, tenemos una transición $((s, \#, s', \Refuter), (w, \sigma^1, s', \Verifier))$ en $Q_{A,A'}$. 
En el caso que el Verificador no pueda emparejar este movimiento en ese juego, tenemos que $(s, \#, s', \Refuter) \in U^3_1$. 
Esto finaliza la prueba ya que $1 \leq 1 + k''$, independientemente del valor de $k''$. 
De lo contrario, el Verificador escoge un movimiento que empareja al de su contrincante, es decir, $((w, \sigma^1, s', \Verifier), (w, \#, w', \Refuter))$ en $\mathcal{Q}_{A,A'}$. 
Además, tenemos una transición $((s', \#, s'', \Refuter), (w', \sigma^1, s'', \Verifier))$ en $\mathcal{Q}_{A',A''}$. 
Pero, esta no puede ser emparejada debido a nuestro supuesto inicial. Por lo tanto, $\delta((s', \#, s'', \Refuter))= (1,3)$, y tenemos que:
\begin{align*}
	\frac{1}{\pr{0}{\delta((s,\#, s'', \Refuter))}}  & = 1\\
							& \leq \frac{1}{\pr{0}{\delta((s, \#, s', \Refuter))}} + 1\\
							& =   \frac{1}{\pr{0}{\delta((s, \#, s', \Refuter))}}  + \frac{1}{\pr{0}{\delta((s', \#, s'', \Refuter))}}
\end{align*}
Para $t=2$,  el razonamiento es similar usando las transiciones de $A''$. 

\item [Paso Inductivo] Para $(i,j) > (1,3)$ la prueba es como sigue. 
Asumamos que $\delta((s, \#, s'', \Refuter)) = (i,j)$. Como $1<i \leq j$, tenemos una transición 
$((s, \#, s'', \Refuter), (w, \sigma^t, w'', \Verifier))$ en $\mathcal{Q}_{A,A''}$. vamos a proceder por casos.

  En el caso $\sigma^t = F^2$ para algún $F \in \Faults''$. Como $\delta((s, \#, s'', \Refuter)) > (1,3)$,
debemos tener una transición $((s, F^2, w'', \Verifier), (s, \#, w'', \Refuter)) \in Q_{A,A''}$ y $\delta((s, \#, w'', \Refuter)) = (i-1,j-2)$. 
Por lo tanto, por definición de $\mathcal{Q}_{A',A''}$, tenemos una transición 
$((s', \#, s'', \Refuter), (s', F^2, w'', \Verifier))$ en $\mathcal{Q}_{A',A''}$. 
En el caso de que $F \in \Faults'$, entonces $F \in \Sigma_{\Faults'}$. 
Si no puede ser emparejada, entonces:
\begin{align*}
\frac{1}{\pr{0}{\delta((s,\#, s'', \Refuter))}}  & \leq 1	\\
							     &= \frac{1}{\pr{0}{\delta((s', \#, s'', \Refuter))}}  \\
							     &\leq  \frac{1}{\pr{0}{\delta((s, \#, s', \Refuter))}} +  \frac{1}{\pr{0}{\delta((s', \#, s'', \Refuter))}}   
\end{align*}
y el resultado se deduce. De lo contrario, tenemos una colección de transiciones  $((s', F^2, w'', \Verifier), (w', \#, w'', \Refuter))$ en $\mathcal{Q}_{A',A''}$. 
Así que, en el juego $\QMStrGame$, tenemos al menos un arco $((s, \#, s', \Refuter), (s, F^2, w', \Verifier))$. 
Entonces, como $((s, F^2, w'', \Verifier), (s, \#, w'', \Refuter)) \in Q_{A,A''}$, también tenemos una transición $((s, F^2, w', \Verifier), (s, \#, w', \Refuter))$ en $Q_{A,A'}$. 
Por hipótesis inductiva, tenemos $\delta((s, \#, w', \Refuter))= i'$ y $\max \{ \delta(v) \mid v \in \post((s', F^2, w'', \Verifier)) \}=i''$ tal que:
\begin{equation}\label{eq:hi1}
\frac{1}{i-1} \leq \frac{1}{i'} + \frac{1}{i''}.
\end{equation} 
y por lo tanto:
\begin{equation}\label{eq:hi1a}
\frac{1}{i} \leq \frac{1}{i'+1} + \frac{1}{i''}.
\end{equation}
Además, notemos que $\delta((s, F^2, w', \Verifier)) \geq (i'+1,j'+1)$ y tenemos una transición (de masking) única desde $(s, F^2, w', \Verifier)$. 
De este modo, 
\begin{equation}\label{eq:hi2}
	\delta((s, \#, s', \Refuter)) \geq (i'+1,j'+2)
\end{equation}
De manera similar, como $F \in \Sigma_{\Faults'}$ tenemos que:
\begin{equation}\label{eq:hi3}
	\delta((s', \#, s'', \Refuter)) \geq (i'',j'+2)
\end{equation}
Por esto, teniendo en cuenta las inecuaciones \ref{eq:hi1a}, \ref{eq:hi2} y \ref{eq:hi3}, obtenemos:
\begin{align*}
	\frac{1}{\pr{0}{\delta((s,\#, s'', \Refuter))}} & = \frac{1}{i} & \text{(Suposición)} \\
									      & \leq \frac{1}{i'+1} + \frac{1}{i''} & \text{Ineq.~\ref{eq:hi1a}} \\
									      &  = \frac{1}{\pr{0}{\delta((s, \#, s', \Refuter))}} +  \frac{1}{\pr{0}{\delta((s', \#, s'', \Refuter))}} &
\end{align*}
	Si $F \notin \Faults'$, entonces debemos tener una transición $((s', F^2, w'', \Verifier), (s', \#, w'', \Refuter))$ en $\mathcal{Q}_{A',A''}$. 
Ahora bien, por hipótesis inductiva, tenemos $\delta((s, \#, s', \Refuter)) = (i',j')$ y $\delta((s', \#, w'', \Refuter)) = (i'',j'')$ tal que 
$\frac{1}{i-1} \leq \frac{1}{i'} + \frac{1}{i''}$. De este modo, $\delta((s', \#, s'', \Refuter)) = (i''+1, j''+2)$ y de forma similar a lo previo, el resultado se deduce.

	En el caso $\sigma^t \neq F^2$. Si $t=1$, entonces tenemos una transición $((s, \#, s'', R), (w, \sigma^1, s'', V))$ en $\mathcal{Q}_{A,A''}$, y 
	como $\delta((s, \#, s'', \Refuter)) > (1,3)$,
debemos tener una transición $((s, \sigma^1, w'', \Verifier), (w, \#, w'', \Refuter))$ en $Q_{A,A''}$ tal que $\delta((s, \#, w'', \Refuter)) = (i,j-2)$. 
Por definición del juego $Q_{A, A'}$, tenemos una transición
$((s, \#, s', \Refuter), (w, \sigma^1, s', \Verifier))$. En el caso que no pueda ser emparejada, entonces esta lleva al resultado que buscamos. De lo contrario, vamos a definir $(i',j') = \max \{\delta(v) \mid v \in \post((w, \sigma^1, s', \Verifier)) \}$. 
Como $\post((w, \sigma^1, s', \Verifier)) \neq \{\ErrorSt\}$, también debe existir una transición $((s', \#, s'', R), (w', \sigma^1, s'', V))$ en $Q_{A',A''}$. 
En el caso que esta no pueda ser emparejada, entonces tenemos $\delta((s', \#, s'', R)) = (1,3)$ y la prueba finaliza. 
En otro caso, definamos $i'' = \max \{\delta(v) \mid v \in \post((w', \sigma^1, s'', V)) \}$ donde por hipótesis inductiva tenemos
\begin{equation}
	\frac{1}{i} \leq \frac{1}{i'} + \frac{1}{i''}
\end{equation}	
	Por esto, 
\begin{equation}
	\frac{1}{\pr{0}{\delta((s, \#, s'', R))}} \leq \frac{1}{\pr{0}{\delta((s, \#, s', R))}} + \frac{1}{\pr{0}{\delta((s', \#, s'', R))}}
\end{equation}	
	Para el caso $t=2$ la prueba es similar.
\end{description}


\qedhere
\end{proof}\\

La prueba para $\DeltaMask^W$ es similar a la de $\DeltaMask$ 
pero utilizando $\QMWeakGame$ en lugar de $\QMStrGame$ y por el Teorema~\ref{thm:weak_thm}.

Las propiedades de reflexividad y desigualdad triangular implican que ambas distancias de masking son semi-métricas dirigidas \cite{CharikarMM06,AlfaroMRS08}. Además, es interesante destacar que la propiedad de desigualdad triangular tiene aplicaciones practicas interesantes. Al momento de desarrollar software critico es bastante común desarrollar una primera versión del software teniendo en cuenta algunas posibles fallas anticipadas. 
Luego, después de una fases de testing y de la ejecución misma del sistema, es posible que mas fallas puedan ser observadas. En consecuencia, el sistema es modificado con nuevos mecanismos de tolerancia a fallas para tolerar estas nuevas fallas observadas. 
El Teorema \ref{thm:triang_ineq} establece que ir midiendo la distancia de masking de estas diferentes versiones del software de manera incremental provee una cota superior de la distancia entre el sistema nominal y la ultima versión de su implementación tolerante a fallas. Esto significa que, si la suma de las distancias obtenidas entre diferentes versiones es un numero pequeño, entonces podemos asegurar que la versión final del sistema exhibirá una masking-tolerancia a fallas aceptable con respecto al sistema nominal.





\section{Trabajo Relacionado} \label{sec:related_work}

This article is a revised and expanded version of a conference paper presented at 
TACAS 2019 \cite{CastroDDP18b} and it extends it as follows:  
(1) it presents formal proofs for all theorems; (2) it describes the problem of computing  
the masking distance considering deterministic and 
non-deterministic systems; (3) it includes a more efficient implementation 
of the \MaskD~tool; and (4) it proposes a more thorough experimental analysis, including more 
instances for each case study and a new case study (Raft).

En los últimos años, se ha incrementado el interés en generalizaciones cuantitativas de la noción booleana de correctitud y sus interrogantes correspondientes en verificación cuantitativa \cite{BokerCHK14,CernyHR12,Henzinger10,Henzinger13}.
El framework descrito en \cite{CernyHR12} es el trabajo mas cercanamente relacionado a nuestro enfoque. 
Los autores generalizan la noción tradicional de relación de simulación a tres versiones diferentes de distancia de simulación: \emph{correctitud}, \emph{cobertura}, y \emph{robustez}.
Estas están definidas utilizando juegos cuantitativos con objetivos \emph{discounted-sum} 
y \emph{mean-payoff}, dos funciones de costo bien conocidas.
Similarmente a ese trabajo, también consideramos distancias entre sistemas puramente discretos (no probabilistas y sin tiempo.

Correctness and coverage distances are concerned with the nominal part of the systems, 
and so faults play no role on them. On the other hand, robustness distance measures how many unexpected errors can be performed by the implementation in such a way that the resulting behavior is tolerated by the specification. So, it can be used to analyze the resilience of the implementation. Note that, robustness
distance can only be applied to correct implementations, that is, implementations that preserve the behavior of the specification but perhaps do not cover all its behavior. As noted in~\cite{CernyHR12}, bisimilarity sometimes implies a distance of $1$. In this sense a greater grade of robustness (as defined in~\cite{CernyHR12}) is achieved by pruning critical points from the specification. Furthermore, the  errors considered in that work are transitions mimicking the original ones but with different labels. In contrast to this, 
 in our approach we consider that faults are injected into the fault-tolerant 
 implementation, where their behaviors are not restricted by the nominal system. 
 This follows the idea of model extension in fault-tolerance where faulty behavior is added 
 to the nominal system. Further, note that when no faults are present, the masking distance between the specification and the implementation is $0$ when they are bisimilar, and it is $1$ otherwise.
It is useful to note that robustness distance of~\cite{CernyHR12} is not reflexive. We believe that all these definitions of distance between systems capture different notions useful for software development, and they can be used together, in a complementary way, to obtain an in-depth
evaluation of fault-tolerant implementations.






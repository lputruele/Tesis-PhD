\section{Introducción} \label{sec:intro_mask}

La tolerancia a fallas es una característica importante del software crítico, y puede ser definida como la capacidad de un sistema para lidiar con eventos inesperados, que pueden ser causados por bugs de programación, interacciones con un ambiente poco cooperativo, mal funcionamiento de hardware, etcétera.
Se pueden encontrar ejemplos de sistemas tolerantes a fallas en casi cualquier parte: protocolos de comunicación, circuitos de hardware, sistemas de aviación, criptomonedas, etcétera.
Por lo tanto, el incremento en la relevancia del software crítico en la vida cotidiana ha llevado a que se renueve el interés en la verificación automática de propiedades de tolerancia a fallas. Sin embargo, una de las dificultades principales a la hora de razonar sobre estos tipos de propiedades se da en su naturaleza cuantitativa, lo cual es cierto incluso en sistemas no probabilistas.
Un ejemplo simple se da con la introducción de redundancia en sistemas críticos. Esta es, sin lugar a dudas, una de las técnicas más utilizadas en tolerancia a fallas.
En la práctica, es común añadir más redundancia en un sistema para incrementar su confiabilidad. Medir este incremento de confiabilidad es un problema central a la hora de evaluar software tolerante a fallas. Por otro lado, no hay un método \emph{de-facto} para caracterizar formalmente propiedades tolerantes a fallas, y por ello se suelen codificar utilizando mecanismos \emph{ad-hoc} como parte del diseño general.

Usualmente el flujo del diseño y verificación de sistemas tolerantes a fallas consiste en definir un modelo nominal (es decir, el programa ``sin fallas'' o ``ideal'') y luego extenderlo con comportamientos defectuosos que se desvían del comportamiento normal descrito por el modelo nominal.
Este modelo extendido representa la manera en la que el sistema opera bajo la ocurrencia de fallas.
Hay diferentes maneras de extender el modelo nominal, el enfoque típico involucra la \emph{inyección de fallas}  \cite{HsuehTI97,IyerNGK10}, es decir, la introducción automática de fallas en el modelo. Una propiedad importante que cualquier modelo extendido debería satisfacer es la preservación del comportamiento normal ante la ausencia de fallas.
En \cite{DemasiCMA17} se propone un enfoque formal alternativo para tratar con el análisis de la tolerancia a fallas. Este enfoque permite un análisis totalmente automático y distingue apropiadamente comportamientos defectuosos y normales. Además, este \textit{framework} es sensible a la inyección de fallas. En ese trabajo se definen tres nociones de relaciones de simulación para caracterizar diferentes tipos de tolerancia a fallas:
tolerancia \emph{enmascarante}, \emph{no enmascarante}, y \emph{seguro ante fallos}, originalmente definidas en \cite{Gartner99}. 

Por otro lado, en los últimos años, se ha logrado un progreso significativo en pos de definir métricas, o nociones de distancias, apropiadas para diversos tipos de modelos cuantitativos, incluyendo sistemas de tiempo real \cite{HenzingerMP05}, modelos probabilistas \cite{DesharnaisGJP04}, y métricas para sistemas lineales y ramificados \cite{CernyHR12,AlfaroFS09,Henzinger13,LarsenFT11,ThraneFL10}. 
Algunos autores han resaltado que estas métricas pueden ser útiles para razonar sobre la robustez de un sistema, un concepto relacionado con la tolerancia a fallas. Particularmente, en \cite{CernyHR12}, la noción tradicional de relación de simulación se generaliza, y se introducen tres distancias de simulación entre sistemas, concretamente \emph{correctitud}, \emph{cobertura}, y \emph{robustez}.
A estas distancias se las define utilizando juegos cuantitativos con objetivos \emph{discounted-sum} y \emph{mean-payoff}.

En este capítulo introducimos una noción de distancia de tolerancia a fallas entre sistemas de transición etiquetados. Intuitivamente, esta distancia mide el grado de tolerancia a fallas exhibido por un sistema candidato. Como fue mencionado anteriormente, existen varios niveles de tolerancia a fallas, aquí nos restringimos al análisis de \emph{tolerancia a fallas enmascarante} ya que usualmente se la considera como el tipo de tolerancia mas beneficioso y por lo tanto es una propiedad altamente deseable en cualquier sistema critico.
A grandes rasgos, un sistema es tolerante a fallas de forma enmascarante cuando es capaz de enmascarar completamente las fallas, no permitiendo que las mismas tengan consecuencias observables para los usuarios. Formalmente, el sistema debe preservar tanto las propiedades de \textit{safety} como las de \textit{liveness} del modelo nominal \cite{Gartner99}. A diferencia de la distancia de robustez definida en \cite{CernyHR12}, la cual mide cuantos errores inesperados son tolerados por una implementación, aquí consideramos una colección especifica de fallas dadas en la implementación y medimos cuantas fallas son toleradas por la implementación de tal manera que puedan ser enmascaradas por los estados del sistema.
También requerimos que el comportamiento normal de la especificación se preserve en la implementación cuando no hay fallas.
Por lo tanto, distinguimos efectivamente entre el modelo nominal, su versión tolerante a fallas,  y el conjunto de fallas para el sistema en cuestión.

Para poder medir el grado de tolerancia a fallas enmascarante de un sistema dado, empezamos caracterizando la tolerancia a fallas enmascarante por medio de relaciones de simulación entre dos sistemas, como se define en \cite{DemasiCMA17}. El primero cumple el rol de especificación del comportamiento deseado (es decir, el modelo nominal) y el segundo cumple el rol de una implementación tolerante a fallas (es decir, el modelo extendido con fallas y mecanismos de tolerancia).
La existencia de una relación de enmascaramiento implica que la implementación enmascara todas las fallas consideradas. Luego, introducimos una caracterización de la simulación de enmascaramiento en términos de juegos y enriquecemos los mismos con objetivos cuantitativos para definir así la noción de \emph{distancia de tolerancia a fallas enmascarante} o \emph{distancia de enmascaramiento}, donde los valores posibles del juego pertenecen al intervalo  $[0,1]$. 
Formalmente, dado un sistema nominal $N$ y su implementación $I$ y sea $\DeltaMask$ nuestra función de distancia, tenemos que $\DeltaMask(N,I)=0$ si la $I$ es tolerante a fallas con enmascaramiento respecto de $N$. Además, mientras mayor el valor, más lejos está la implementación de la especificación en términos de la distancia de tolerancia a fallas enmascarante. De esta forma, una distancia mayor decrementa notablemente el grado de tolerancia a fallas. A su vez, $\DeltaMask(N,I)=1$ cuando el modelo nominal $N$ y $I \backslash F$ no son bisimilares, donde $I\backslash F$ se comporta como la implementación $I$ cuando todas las acciones en $F$ están deshabilitadas ($\backslash$ es el operador de restricción de Milner).
Entonces, para un modelo nominal $N$ y dos implementaciones tolerantes a fallas diferentes $I_1$ y $I_2$, nuestra distancia asegura que  $\DeltaMask(N,I_1)<\DeltaMask(N,I_2)$ cuando $I_1$ tolera mas fallas que $I_2$.
También proporcionamos una versión débil de la simulación de enmascaramiento, la cual hace posible tratar con sistemas más complejos compuestos por varios componentes que interactúan entre si. Probamos que la distancia de enmascaramiento es una semi-métrica dirigida, es decir, que satisface dos propiedades básicas de cualquier distancia: reflexividad y la desigualdad triangular.

Finalmente, hemos implementado nuestra técnica en una herramienta que toma como argumentos un modelo nominal y su implementación tolerante a fallas, y computa automáticamente la distancia de enmascaramiento entre estos.
Hemos utilizado esta herramienta para medir tolerancia a fallas enmascarante en múltiples instancias de varios casos de estudio: una celda de memoria redundante \cite{DemasiCMA17}, una variante del problema de los filósofos comensales \cite{Dijkstra71}, el protocolo de comunicación BRP (\emph{Bounded Retransmission Protocol}) \cite{GrooteP96}, redundancia N-Modular \cite{ShoomanBook}, el problema de los generales bizantinos \cite{LamportSP82} y un subproblema del protocolo de consenso Raft \cite{OngaroO14} para lograr una replicación consistente de datos.
Todos los casos de estudio mencionados son ejemplos típicos de sistemas tolerantes a fallas. Un punto interesante sobre nuestra implementación es que, para sistemas deterministas, la distancia de enmascaramiento entre dos sistemas puede ser computada recurriendo a un algoritmo de camino más corto. Mientras que en el caso de sistemas no deterministas, se aplica un algoritmo de punto fijo basado en la búsqueda primero a lo ancho (\emph{breadth first search}), lo cual es menos eficiente, sin embargo en ambos casos el algoritmo es polinomial. Los detalles de la herramienta quedan delegados al Capítulo~\ref{cap:tool}.

El capítulo está estructurado de la siguiente manera. La sección \ref{sec:masking_dist_mask} presenta la definición de simulación de enmascaramiento (fuerte y débil) y la caracterización de juegos correspondiente.
En la Sección \ref{sec:QuantMask_mask} presentamos la definición formal de distancia de enmascaramiento que se construye a partir de juegos de simulación cuantitativos, presentamos también los algoritmos para computarla, y también probamos sus propiedades elementales.
Se describe en la Sección \ref{sec:experimental_eval_mask} la evaluación experimental sobre varios casos de estudio conocidos. 
Finalmente en la Sección \ref{sec:related_work_mask} discutimos el trabajo relacionado. 